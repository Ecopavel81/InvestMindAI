import os
import numpy as np
import pandas as pd
from typing import Dict, List, Tuple
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import joblib # –î–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–∫–µ–π–ª–µ—Ä–æ–≤

# –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ TensorFlow/Keras
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential, load_model # load_model –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏

class TradingSignalGenerator:
    """
    –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Ç–æ—Ä–≥–æ–≤—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤ —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º —Ç–æ—á–µ–∫ –≤—Ö–æ–¥–∞/–≤—ã—Ö–æ–¥–∞
    –∏ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ–º –ø–æ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—é —Ä–∏—Å–∫/–ø—Ä–∏–±—ã–ª—å
    """
    
    def __init__(self):
        self.tp_ratios = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]  # –†–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ –¢–ü
        self.min_rr_ratio = 3.0  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –ø—Ä–∏–±—ã–ª—å/—Ä–∏—Å–∫ –¥–ª—è "–≥–æ—Ä—è—á–∏—Ö" —Å–¥–µ–ª–æ–∫
        
    def calculate_entry_exit_points(self, current_price: float, predicted_price: float, 
                                  atri: float, level_info: Dict) -> Dict:
        """
        –†–∞—Å—á–µ—Ç —Ç–æ—á–µ–∫ –≤—Ö–æ–¥–∞ –∏ –≤—ã—Ö–æ–¥–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∏ ATRI
        
        Args:
            current_price: —Ç–µ–∫—É—â–∞—è —Ü–µ–Ω–∞
            predicted_price: –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è —Ü–µ–Ω–∞
            atri: –¥–Ω–µ–≤–Ω–æ–π ATRI
            level_info: –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± —É—Ä–æ–≤–Ω—è—Ö
            
        Returns:
            dict —Å —Ç–æ—á–∫–∞–º–∏ –≤—Ö–æ–¥–∞/–≤—ã—Ö–æ–¥–∞ –∏ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ–º
        """
        direction = 1 if predicted_price > current_price else -1
        price_change = abs(predicted_price - current_price)
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–æ—á–∫–∏ –≤—Ö–æ–¥–∞
        entry_price = current_price
        
        # –°—Ç–æ–ø-–ª–æ—Å—Å –Ω–∞ –æ—Å–Ω–æ–≤–µ ATRI –∏ –±–ª–∏–∑–æ—Å—Ç–∏ –∫ —É—Ä–æ–≤–Ω—è–º
        if direction == 1:  # Long –ø–æ–∑–∏—Ü–∏—è
            # –°—Ç–æ–ø –Ω–∏–∂–µ –±–ª–∏–∂–∞–π—à–µ–π –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –∏–ª–∏ –Ω–∞ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–∏ ATRI
            support_level = current_price * (1 - level_info['nearest_support_dist'])
            atri_stop = current_price - atri
            stop_loss = min(support_level, atri_stop)
        else:  # Short –ø–æ–∑–∏—Ü–∏—è
            # –°—Ç–æ–ø –≤—ã—à–µ –±–ª–∏–∂–∞–π—à–µ–≥–æ —Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏—è –∏–ª–∏ –Ω–∞ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–∏ ATRI
            resistance_level = current_price * (1 + level_info['nearest_resistance_dist'])
            atri_stop = current_price + atri
            stop_loss = max(resistance_level, atri_stop)
        
        risk = abs(entry_price - stop_loss)
        
        # –†–∞—Å—á–µ—Ç —É—Ä–æ–≤–Ω–µ–π —Ç–µ–π–∫-–ø—Ä–æ—Ñ–∏—Ç–∞
        take_profits = {}
        hot_deals = []
        
        for ratio in self.tp_ratios:
            if direction == 1:
                tp_price = entry_price + (risk * ratio)
            else:
                tp_price = entry_price - (risk * ratio)
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç–∏–∂–∏–º–æ—Å—Ç–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ ATRI
            distance_to_tp = abs(tp_price - current_price)
            atri_multiplier = distance_to_tp / atri
            
            # –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è –¢–ü (—ç–≤—Ä–∏—Å—Ç–∏–∫–∞)
            if atri_multiplier <= 1:
                probability = 0.8
            elif atri_multiplier <= 2:
                probability = 0.6
            elif atri_multiplier <= 3:
                probability = 0.4
            else:
                probability = 0.2
            
            take_profits[f"TP_{ratio}"] = {
                'price': tp_price,
                'ratio': ratio,
                'distance_atri': atri_multiplier,
                'probability': probability,
                'profit': risk * ratio,
                'rr_ratio': ratio
            }
            
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ "–≥–æ—Ä—è—á–∏—Ö" —Å–¥–µ–ª–æ–∫
            if ratio >= self.min_rr_ratio and probability >= 0.4:
                hot_deals.append({
                    'tp_level': f"TP_{ratio}",
                    'rr_ratio': ratio,
                    'probability': probability,
                    'profit_potential': risk * ratio
                })
        
        return {
            'direction': 'LONG' if direction == 1 else 'SHORT',
            'entry_price': entry_price,
            'stop_loss': stop_loss,
            'risk': risk,
            'take_profits': take_profits,
            'hot_deals': sorted(hot_deals, key=lambda x: x['rr_ratio'], reverse=True),
            'atri_daily': atri
        }
    
    def rank_signals(self, signals: List[Dict]) -> List[Dict]:
        """
        –†–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–æ—Ä–≥–æ–≤—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤ –ø–æ –ø—Ä–∏–≤–ª–µ–∫–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        
        Args:
            signals: —Å–ø–∏—Å–æ–∫ —Ç–æ—Ä–≥–æ–≤—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤
            
        Returns:
            –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Å–∏–≥–Ω–∞–ª–æ–≤
        """
        def calculate_signal_score(signal):
            # –ë–∞–∑–æ–≤—ã–π —Å–∫–æ—Ä –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –≥–æ—Ä—è—á–∏—Ö —Å–¥–µ–ª–æ–∫
            hot_deals_count = len(signal['hot_deals'])
            base_score = hot_deals_count * 10
            
            # –ë–æ–Ω—É—Å –∑–∞ –≤—ã—Å–æ–∫–æ–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ R/R
            if signal['hot_deals']:
                max_rr = max(deal['rr_ratio'] for deal in signal['hot_deals'])
                base_score += max_rr * 5
            
            # –ë–æ–Ω—É—Å –∑–∞ –≤—ã—Å–æ–∫—É—é –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å
            avg_probability = np.mean([deal['probability'] for deal in signal['hot_deals']]) if signal['hot_deals'] else 0
            base_score += avg_probability * 20
            
            return base_score
        
        for signal in signals:
            signal['score'] = calculate_signal_score(signal)
        
        return sorted(signals, key=lambda x: x['score'], reverse=True)


class CriptoPredictionNN:
    """
    –£–ª—É—á—à–µ–Ω–Ω–∞—è –Ω–µ–π—Ä–æ—Å–µ—Ç—å –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Ü–µ–Ω—ã —Å —Å–∏—Å—Ç–µ–º–æ–π —Ç–æ—Ä–≥–æ–≤—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤
    """

    def __init__(self, days_level, lookback_period=20, prediction_horizon=5,
                 prediction_type='price', model_save_dir='models'):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Ü–µ–Ω—ã

        Args:
            days_level_analyzer: —ç–∫–∑–µ–º–ø–ª—è—Ä –∫–ª–∞—Å—Å–∞ DaysLevel
            lookback_period: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–µ—Ä–∏–æ–¥–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏—Å—Ç–æ—Ä–∏–∏
            prediction_horizon: –≥–æ—Ä–∏–∑–æ–Ω—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–µ—Ä–∏–æ–¥–æ–≤ –≤–ø–µ—Ä–µ–¥)
            prediction_type: —Ç–∏–ø –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è ('price' –∏–ª–∏ 'change')
            model_save_dir: –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π
        """
        self.days_level = days_level
        self.lookback_period = lookback_period
        self.prediction_horizon = prediction_horizon
        self.prediction_type = prediction_type
        self.is_trained = False
        self.model_save_dir = model_save_dir

        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –º–æ–¥–µ–ª–µ–π
        os.makedirs(model_save_dir, exist_ok=True)

        # –°–∫–µ–π–ª–µ—Ä—ã –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö
        self.price_scaler = MinMaxScaler()
        self.feature_scaler = StandardScaler()

        # –ú–æ–¥–µ–ª—å
        self.model = None

        # –ò—Å—Ç–æ—Ä–∏—è –æ–±—É—á–µ–Ω–∏—è
        self.training_history = None

        # –î–∞–Ω–Ω—ã–µ
        self.X_train = None
        self.X_test = None
        self.y_train = None
        self.y_test = None
        
        # –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Ç–æ—Ä–≥–æ–≤—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤
        self.signal_generator = TradingSignalGenerator()

    def _calculate_distance_to_levels(self, current_price: float, levels: List[Tuple]) -> Dict:
        """
        –†–∞—Å—á–µ—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è –æ—Ç —Ç–µ–∫—É—â–µ–π —Ü–µ–Ω—ã –¥–æ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —É—Ä–æ–≤–Ω–µ–π

        Args:
            current_price: —Ç–µ–∫—É—â–∞—è —Ü–µ–Ω–∞
            levels: —Å–ø–∏—Å–æ–∫ —É—Ä–æ–≤–Ω–µ–π [(date, level, strength, timeframe, type, direction)]

        Returns:
            dict —Å —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è–º–∏ –∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º–∏ —É—Ä–æ–≤–Ω–µ–π
        """
        if not levels:
            return {
                'nearest_support_dist': 0.01,
                'nearest_resistance_dist': 0.01,
                'nearest_support_strength': 5,
                'nearest_resistance_strength': 5,
                'nearest_mirror_dist': 0.02,
                'nearest_mirror_strength': 6,
                'total_levels_above': 3,
                'total_levels_below': 2,
                'weighted_support_strength': 15,
                'weighted_resistance_strength': 12,
            }

        supports = []
        resistances = []
        mirrors = []

        for level_data in levels:
            _, level, strength, timeframe, level_type, direction = level_data

            if level_type == 'mirror':
                mirrors.append((level, strength))
            elif level < current_price:
                supports.append((level, strength))
            else:
                resistances.append((level, strength))

        # –ë–ª–∏–∂–∞–π—à–∏–µ —É—Ä–æ–≤–Ω–∏
        nearest_support = max(supports, key=lambda x: x[0]) if supports else (0, 0)
        nearest_resistance = min(resistances, key=lambda x: x[0]) if resistances else (999999, 0)
        nearest_mirror = min(mirrors, key=lambda x: abs(x[0] - current_price)) if mirrors else (0, 0)

        # –†–∞—Å—á–µ—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π
        support_dist = (current_price - nearest_support[0]) / current_price if nearest_support[0] > 0 else 0.05
        resistance_dist = (nearest_resistance[0] - current_price) / current_price if nearest_resistance[0] > 0 else 0.05
        mirror_dist = abs(nearest_mirror[0] - current_price) / current_price if nearest_mirror[0] > 0 else 0.02

        # –í–∑–≤–µ—à–µ–Ω–Ω–∞—è —Å–∏–ª–∞ —É—Ä–æ–≤–Ω–µ–π
        weighted_support = sum(s * (1 / (1 + abs(l - current_price))) for l, s in supports) if supports else 0
        weighted_resistance = sum(s * (1 / (1 + abs(l - current_price))) for l, s in resistances) if resistances else 0

        return {
            'nearest_support_dist': support_dist,
            'nearest_resistance_dist': resistance_dist,
            'nearest_support_strength': nearest_support[1],
            'nearest_resistance_strength': nearest_resistance[1],
            'nearest_mirror_dist': mirror_dist,
            'nearest_mirror_strength': nearest_mirror[1],
            'total_levels_above': len(resistances),
            'total_levels_below': len(supports),
            'weighted_support_strength': weighted_support,
            'weighted_resistance_strength': weighted_resistance
        }

    def _calculate_volatility_features(self, data: pd.DataFrame, window: int = 10) -> Dict:
        """
        –†–∞—Å—á–µ—Ç —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏

        Args:
            data: DataFrame —Å OHLC –¥–∞–Ω–Ω—ã–º–∏
            window: –æ–∫–Ω–æ –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞

        Returns:
            dict —Å —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º–∏ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
        """
        if len(data) < window:
            return {
                'volatility_ratio': 0.03,
                'is_accumulation': False,
                'price_range_ratio': 0.05,
                'volume_trend': 0.01
            }

        # –°—Ä–µ–¥–Ω–∏–π ATRI –∑–∞ –ø–µ—Ä–∏–æ–¥
        avg_atri = data['atri'].rolling(window=window).mean().iloc[-1]
        current_volatility = data['atri'].iloc[-1]

        # –û—Ç–Ω–æ—à–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–π –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ –∫ —Å—Ä–µ–¥–Ω–µ–π
        volatility_ratio = current_volatility / avg_atri if avg_atri > 0 else 0

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–∞–∫–æ–ø–ª–µ–Ω–∏–µ (–≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å < 0.5 ATRI)
        is_accumulation = volatility_ratio < 0.5

        # –î–∏–∞–ø–∞–∑–æ–Ω —Ü–µ–Ω
        price_range = (data['high'].iloc[-1] - data['low'].iloc[-1]) / data['close'].iloc[-1]
        avg_price_range = ((data['high'] - data['low']) / data['close']).rolling(window=window).mean().iloc[-1]
        price_range_ratio = price_range / avg_price_range if avg_price_range > 0 else 0

        # –¢—Ä–µ–Ω–¥ –æ–±—ä–µ–º–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å)
        volume_trend = 0
        if 'volume' in data.columns:
            recent_volume = data['volume'].iloc[-window:].mean()
            prev_volume = data['volume'].iloc[-2*window:-window].mean()
            volume_trend = (recent_volume - prev_volume) / prev_volume if prev_volume > 0 else 0

        return {
            'volatility_ratio': volatility_ratio,
            'is_accumulation': is_accumulation,
            'price_range_ratio': price_range_ratio,
            'volume_trend': volume_trend
        }

    def _determine_strategy(self, current_price: float, predicted_price: float,
                              level_info: Dict, volatility_info: Dict, daily_atri: float) -> str:
        """
        –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–æ—Ä–≥–æ–≤–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è, –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± —É—Ä–æ–≤–Ω—è—Ö –∏ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏.
        """
        price_change_abs = abs(predicted_price - current_price)
        price_change_percent = price_change_abs / current_price

        # --- Level Proximity ---
        # Convert absolute distances to ATRI multiples for better context
        nearest_support_dist_atri = level_info['nearest_support_dist'] * current_price / daily_atri
        nearest_resistance_dist_atri = level_info['nearest_resistance_dist'] * current_price / daily_atri
        nearest_mirror_dist_atri = level_info['nearest_mirror_dist'] * current_price / daily_atri

        # Define thresholds in terms of ATRI for "nearness"
        NEAR_LEVEL_ATRI_THRESHOLD = 0.5 # e.g., within 0.5 ATRI
        
        near_support = nearest_support_dist_atri < NEAR_LEVEL_ATRI_THRESHOLD and level_info['nearest_support_strength'] > 0
        near_resistance = nearest_resistance_dist_atri < NEAR_LEVEL_ATRI_THRESHOLD and level_info['nearest_resistance_strength'] > 0
        near_mirror = nearest_mirror_dist_atri < NEAR_LEVEL_ATRI_THRESHOLD and level_info['nearest_mirror_strength'] > 0

        # --- Volatility and Consolidation Checks ---
        # Low volatility: This is already captured by volatility_info['is_accumulation']
        is_low_volatility = volatility_info['is_accumulation'] # True if volatility_ratio < 0.5

        # Check for "Dojis" (small body, long wicks) - Requires adding a feature for candle body size or shape
        # For simplicity, we'll assume `is_doji_pattern_recent` is a feature you might add.
        # is_doji_pattern_recent = self._check_doji_pattern(data, current_index, window=3) # Example
        
        # Low volume - requires a specific check over last 3-4 days
        # This also needs to be a feature calculated and passed in volatility_info or a new 'market_conditions' dict.
        # For now, let's assume `has_low_recent_volume` is a feature.
        has_low_recent_volume = volatility_info['volume_trend'] < 0.005 # Example: low positive or negative trend

        # --- Strategy Logic ---

        # Strategy 1: Price targeting nearest strong level (magnet effect)
        if price_change_abs < daily_atri * 2: # Only consider if predicted change is relatively small
            if near_support and predicted_price > current_price:
                return "–û–∂–∏–¥–∞–µ–º –æ—Ç—Å–∫–æ–∫ –æ—Ç –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –∫ –±–ª–∏–∂–∞–π—à–µ–º—É —É—Ä–æ–≤–Ω—é"
            if near_resistance and predicted_price < current_price:
                return "–û–∂–∏–¥–∞–µ–º –æ—Ç—Å–∫–æ–∫ –æ—Ç —Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏—è –∫ –±–ª–∏–∂–∞–π—à–µ–º—É —É—Ä–æ–≤–Ω—é"

        # Strategy 2: Breakout from Consolidation (Low Volatility, Dojis, Low Volume)
        # Target: More than 3-4 ATRI move, potentially to a weekly level
        BREAKOUT_ATRI_TARGET = 3.5 # Minimum target for a breakout in ATRI multiples

        if is_low_volatility and has_low_recent_volume: # Add `is_doji_pattern_recent` if implemented
            target_level = None
            target_distance_atri = 0

            # Find the next significant weekly level in the predicted direction
            if predicted_price > current_price: # Bullish breakout
                resistances = [lvl for lvl in self.days_level.get_strongest_levels(timeframes=['1W']) if lvl[1] > current_price]
                if resistances:
                    target_level = min(resistances, key=lambda x: x[1]) # Nearest weekly resistance above
                    target_distance_atri = (target_level[1] - current_price) / daily_atri if daily_atri > 0 else 0
            elif predicted_price < current_price: # Bearish breakout
                supports = [lvl for lvl in self.days_level.get_strongest_levels(timeframes=['1W']) if lvl[1] < current_price]
                if supports:
                    target_level = max(supports, key=lambda x: x[1]) # Nearest weekly support below
                    target_distance_atri = (current_price - target_level[1]) / daily_atri if daily_atri > 0 else 0

            if target_level and target_distance_atri >= BREAKOUT_ATRI_TARGET and price_change_abs > BREAKOUT_ATRI_TARGET * daily_atri:
                # Check if predicted price moves towards this target significantly
                if (predicted_price > current_price and predicted_price <= target_level[1]) or \
                  (predicted_price < current_price and predicted_price >= target_level[1]):
                    return f"–ü—Ä–æ—Ä—ã–≤ –∏–∑ –∫–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏–∏ –∫ –Ω–µ–¥–µ–ª—å–Ω–æ–º—É —É—Ä–æ–≤–Ω—é {target_level[1]:.2f} ({target_distance_atri:.1f} ATRI)"

        # --- Existing Strategies (as in your original code) ---
        if near_support and level_info['nearest_support_strength'] > 5:
            if predicted_price > current_price:
                return "–û—Ç–±–æ–π –æ—Ç —Å–∏–ª—å–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏ - –ø–æ–∫—É–ø–∫–∞"
            else:
                return "–í–æ–∑–º–æ–∂–Ω—ã–π –ø—Ä–æ–±–æ–π —É—Ä–æ–≤–Ω—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏ - –ø—Ä–æ–¥–∞–∂–∞"

        if near_resistance and level_info['nearest_resistance_strength'] > 5:
            if predicted_price < current_price:
                return "–û—Ç–±–æ–π –æ—Ç —Å–∏–ª—å–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è —Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏—è - –ø—Ä–æ–¥–∞–∂–∞"
            else:
                return "–í–æ–∑–º–æ–∂–Ω—ã–π –ø—Ä–æ–±–æ–π —É—Ä–æ–≤–Ω—è —Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏—è - –ø–æ–∫—É–ø–∫–∞"

        if near_mirror and level_info['nearest_mirror_strength'] > 3:
            mirror_distance = level_info['nearest_mirror_dist'] * current_price
            if predicted_price > current_price:
                return f"–û—Ç—Ä–∞–±–æ—Ç–∫–∞ –∑–µ—Ä–∫–∞–ª—å–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è –≤–≤–µ—Ä—Ö - —Ü–µ–ª—å +{mirror_distance:.2f}"
            else:
                return f"–û—Ç—Ä–∞–±–æ—Ç–∫–∞ –∑–µ—Ä–∫–∞–ª—å–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è –≤–Ω–∏–∑ - —Ü–µ–ª—å -{mirror_distance:.2f}"

        if price_change_percent > 0.02 or price_change_percent < -0.02: # Significant movement > 2%
            direction = "–ø–æ–∫—É–ø–∫–∞" if predicted_price > current_price else "–ø—Ä–æ–¥–∞–∂–∞"
            return f"–ó–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ –¥–≤–∏–∂–µ–Ω–∏–µ - {direction}"

        return "–ë–æ–∫–æ–≤–æ–µ –¥–≤–∏–∂–µ–Ω–∏–µ - –æ–∂–∏–¥–∞–Ω–∏–µ"
    
    
    def predict_with_trading_signals(self, data: pd.DataFrame, current_index: int = None) -> Dict:
        # ... (previous code) ...

        # Ensure ATRI column exists or calculate it for this specific data slice
        if 'atri' not in data.columns or pd.isna(data['atri'].iloc[current_index]):
            temp_data_for_atri = data.iloc[max(0, current_index - self.lookback_period - 14):current_index + 1].copy() # Need more data for ATRI calculation
            # Calculate ATRI on this temp_data_for_atri and assign it back to the original 'data' DataFrame at the current index
            # This is a bit tricky with partial calculation; ideally, ATRI is pre-calculated for the entire 'data'
            # For a robust solution, ensure 'atri' is fully pre-calculated on 'data' before calling this method.
            # As a temporary workaround, if it's missing, we'll try to calculate it for the window.
            if not temp_data_for_atri.empty:
                calculated_atri_series = self._calculate_atri(temp_data_for_atri)
                # Assign the last calculated ATRI value back to the original DataFrame
                if not calculated_atri_series.empty:
                    data.loc[data.index[current_index], 'atri'] = calculated_atri_series.iloc[-1]
                else:
                    data.loc[data.index[current_index], 'atri'] = 0.01 # Fallback
            else:
                data.loc[data.index[current_index], 'atri'] = 0.01 # Fallback


        daily_atri = data['atri'].iloc[current_index] if 'atri' in data.columns and not pd.isna(data['atri'].iloc[current_index]) else 0.01

        # ... (previous code) ...

        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ - NOW PASS daily_atri
        strategy = self._determine_strategy(current_price, predicted_price, level_info, volatility_info, daily_atri)

        return {
            'current_price': current_price,
            'predicted_price': predicted_price,
            'predicted_change': predicted_change,
            'predicted_change_percent': predicted_change * 100,
            'strategy': strategy,
            'level_info': level_info,
            'volatility_info': volatility_info,
            'confidence': self._calculate_confidence(features_scaled),
            'trading_signals': trading_signals,
            'daily_atri': daily_atri
        }
    
    def _create_features(self, data: pd.DataFrame, index: int) -> np.ndarray:
        """
        –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –Ω–µ–π—Ä–æ—Å–µ—Ç–∏

        Args:
            data: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
            index: –∏–Ω–¥–µ–∫—Å —Ç–µ–∫—É—â–µ–π –ø–æ–∑–∏—Ü–∏–∏

        Returns:
            –º–∞—Å—Å–∏–≤ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        """
        if index < self.lookback_period:
            return None

        # –ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ —Ü–µ–Ω—ã
        historical_prices = data['close'].iloc[index-self.lookback_period:index].values
        price_returns = np.diff(historical_prices) / historical_prices[:-1]

        # –¢–µ–∫—É—â–∞—è —Ü–µ–Ω–∞
        current_price = data['close'].iloc[index]

        # –ü–æ–ª—É—á–µ–Ω–∏–µ —É—Ä–æ–≤–Ω–µ–π
        strongest_levels = self.days_level.get_strongest_levels(timeframes=['1H', '4H', '1D'], top_n=20)

        # –†–∞—Å—á–µ—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π –¥–æ —É—Ä–æ–≤–Ω–µ–π
        level_features = self._calculate_distance_to_levels(current_price, strongest_levels)

        # –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
        volatility_features = self._calculate_volatility_features(
            data.iloc[index-self.lookback_period:index+1]
        )

        # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
        rsi = self._calculate_rsi(historical_prices)
        macd, macd_signal = self._calculate_macd(historical_prices)

        # –°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –≤–µ–∫—Ç–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        features = np.concatenate([
            # –ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏
            price_returns,

            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Ü–µ–Ω
            [np.mean(price_returns), np.std(price_returns), np.min(price_returns), np.max(price_returns)],

            # –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ —É—Ä–æ–≤–Ω–µ–π
            [level_features['nearest_support_dist'],
             level_features['nearest_resistance_dist'],
             level_features['nearest_support_strength'],
             level_features['nearest_resistance_strength'],
             level_features['nearest_mirror_dist'],
             level_features['nearest_mirror_strength'],
             level_features['total_levels_above'],
             level_features['total_levels_below'],
             level_features['weighted_support_strength'],
             level_features['weighted_resistance_strength']],

            # –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
            [volatility_features['volatility_ratio'],
             float(volatility_features['is_accumulation']),
             volatility_features['price_range_ratio'],
             volatility_features['volume_trend']],

            # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
            [rsi, macd, macd_signal],

            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
            [current_price / np.mean(historical_prices),  # –û—Ç–Ω–æ—à–µ–Ω–∏–µ –∫ —Å—Ä–µ–¥–Ω–µ–π —Ü–µ–Ω–µ
             (current_price - np.min(historical_prices)) / (np.max(historical_prices) - np.min(historical_prices))]  # –ü–æ–∑–∏—Ü–∏—è –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ
        ])

        return features

    def _calculate_rsi(self, prices: np.ndarray, period: int = 14) -> float:
        """–†–∞—Å—á–µ—Ç RSI"""
        if len(prices) < period + 1:
            return 50.0

        deltas = np.diff(prices)
        gains = np.where(deltas > 0, deltas, 0)
        losses = np.where(deltas < 0, -deltas, 0)

        avg_gain = np.mean(gains[-period:])
        avg_loss = np.mean(losses[-period:])

        if avg_loss == 0:
            return 100.0

        rs = avg_gain / avg_loss
        rsi = 100 - (100 / (1 + rs))

        return rsi

    def _calculate_macd(self, prices: np.ndarray, fast: int = 12, slow: int = 26, signal: int = 9) -> Tuple[float, float]:
        """–†–∞—Å—á–µ—Ç MACD"""
        if len(prices) < slow:
            return 0.0, 0.0

        ema_fast = self._ema(prices, fast)
        ema_slow = self._ema(prices, slow)

        macd = ema_fast - ema_slow

        # –î–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç–æ–µ —Å–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ –≤–º–µ—Å—Ç–æ EMA –¥–ª—è —Å–∏–≥–Ω–∞–ª—å–Ω–æ–π –ª–∏–Ω–∏–∏
        if len(prices) >= slow + signal:
            macd_line = []
            for i in range(slow-1, len(prices)):
                ema_f = self._ema(prices[:i+1], fast)
                ema_s = self._ema(prices[:i+1], slow)
                macd_line.append(ema_f - ema_s)

            macd_signal = np.mean(macd_line[-signal:])
        else:
            macd_signal = 0.0

        return macd, macd_signal

    def _ema(self, prices: np.ndarray, period: int) -> float:
        """–†–∞—Å—á–µ—Ç —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–≥–æ —Å–∫–æ–ª—å–∑—è—â–µ–≥–æ —Å—Ä–µ–¥–Ω–µ–≥–æ"""
        if len(prices) < period:
            return np.mean(prices)

        alpha = 2.0 / (period + 1)
        ema = prices[0]

        for price in prices[1:]:
            ema = alpha * price + (1 - alpha) * ema

        return ema

    def prepare_data(self, data: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:
        """
        –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è

        Args:
            data: DataFrame —Å OHLC –¥–∞–Ω–Ω—ã–º–∏

        Returns:
            Tuple[X, y] - –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏ —Ü–µ–ª–µ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        """
        X, y = [], []

        for i in range(self.lookback_period, len(data) - self.prediction_horizon):
            # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è —Ç–µ–∫—É—â–µ–π –ø–æ–∑–∏—Ü–∏–∏
            features = self._create_features(data, i)
            if features is None:
                continue

            # –¶–µ–ª–µ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
            current_price = data['close'].iloc[i]
            future_price = data['close'].iloc[i + self.prediction_horizon]

            if self.prediction_type == 'price':
                target = future_price
            else:  # change
                target = (future_price - current_price) / current_price

            X.append(features)
            y.append(target)

        return np.array(X), np.array(y)

    def create_model(self, input_shape: int) -> keras.Model:
        """
        –°–æ–∑–¥–∞–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –Ω–µ–π—Ä–æ—Å–µ—Ç–∏

        Args:
            input_shape: —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –≤—Ö–æ–¥–Ω–æ–≥–æ –≤–µ–∫—Ç–æ—Ä–∞

        Returns:
            –º–æ–¥–µ–ª—å Keras
        """
        model = keras.Sequential([
            # –í—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π
            layers.Input(shape=(input_shape,)),

            # –ü–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–µ —Å–ª–æ–∏
            layers.Dense(256, activation='relu'),
            layers.BatchNormalization(),
            layers.Dropout(0.3),

            # –°–∫—Ä—ã—Ç—ã–µ —Å–ª–æ–∏
            layers.Dense(128, activation='relu'),
            layers.BatchNormalization(),
            layers.Dropout(0.3),

            layers.Dense(64, activation='relu'),
            layers.BatchNormalization(),
            layers.Dropout(0.2),

            layers.Dense(32, activation='relu'),
            layers.Dropout(0.2),

            layers.Dense(16, activation='relu'),

            # –í—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π - –æ–¥–∏–Ω –≤—ã—Ö–æ–¥ –¥–ª—è –æ–¥–Ω–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            layers.Dense(1, activation='linear')
        ])

        # –ö–æ–º–ø–∏–ª—è—Ü–∏—è –º–æ–¥–µ–ª–∏
        model.compile(
            optimizer=keras.optimizers.Adam(learning_rate=0.001),
            loss='mse',
            metrics=['mae']
        )

        return model

    def train(self, data: pd.DataFrame, epochs: int = 100, batch_size: int = 32,
              validation_split: float = 0.2, verbose: int = 1):
        """
        –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏

        Args:
            data: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
            epochs: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö –æ–±—É—á–µ–Ω–∏—è
            batch_size: —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞
            validation_split: –¥–æ–ª—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
            verbose: —É—Ä–æ–≤–µ–Ω—å –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏ –≤—ã–≤–æ–¥–∞
        """
        print("–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
        X, y = self.prepare_data(data)

        if len(X) == 0:
            raise ValueError("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")

        print(f"–†–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏: {X.shape}")
        print(f"–†–∞–∑–º–µ—Ä —Ü–µ–ª–µ–≤–æ–≥–æ –≤–µ–∫—Ç–æ—Ä–∞: {y.shape}")

        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ü–µ–ª–µ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        if self.prediction_type == 'price':
            y = y.reshape(-1, 1)
            y_scaled = self.price_scaler.fit_transform(y)
        else:
            y_scaled = y.reshape(-1, 1)

        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        X_scaled = self.feature_scaler.fit_transform(X)

        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏
        X_train, X_test, y_train, y_test = train_test_split(
            X_scaled, y_scaled, test_size=0.2, random_state=42, shuffle=False
        )

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∞—Ç—Ä–∏–±—É—Ç—ã
        self.X_train, self.X_test = X_train, X_test
        self.y_train, self.y_test = y_train, y_test

        # –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
        self.model = self.create_model(X.shape[1])

        # Callbacks –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        callbacks = [
            keras.callbacks.EarlyStopping(
                monitor='val_loss',
                patience=20,
                restore_best_weights=True
            ),
            keras.callbacks.ReduceLROnPlateau(
                monitor='val_loss',
                factor=0.5,
                patience=10,
                min_lr=1e-6
            )
        ]

        # –û–±—É—á–µ–Ω–∏–µ
        print("–ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è...")
        self.training_history = self.model.fit(
            X_train, y_train,
            validation_split=validation_split,
            epochs=epochs,
            callbacks=callbacks,
            batch_size=batch_size,
            verbose=verbose
        )

        # –û—Ü–µ–Ω–∫–∞ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ
        test_loss, test_mae = self.model.evaluate(X_test, y_test, verbose=0)
        print(f"\n–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ:")
        print(f"MSE: {test_loss:.6f}")
        print(f"MAE: {test_mae:.6f}")

        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ
        y_pred = self.model.predict(X_test, verbose=0)

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        rmse = np.sqrt(mean_squared_error(y_test, y_pred))
        print(f"RMSE: {rmse:.6f}")

        self.is_trained = True

        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        self.save_model_auto()

        return self.training_history

    def predict_with_trading_signals(self, data: pd.DataFrame, current_index: int = None) -> Dict:
        """
        –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ü–µ–Ω—ã —Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π —Ç–æ—Ä–≥–æ–≤—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤

        Args:
            data: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
            current_index: –∏–Ω–¥–µ–∫—Å –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è (–µ—Å–ª–∏ None, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–æ—Å–ª–µ–¥–Ω–∏–π)

        Returns:
            dict —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ–º –∏ —Ç–æ—Ä–≥–æ–≤—ã–º–∏ —Å–∏–≥–Ω–∞–ª–∞–º–∏
        """
        if not self.is_trained:
            raise ValueError("–ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞")

        if current_index is None:
            current_index = len(data) - 1

        # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        features = self._create_features(data, current_index)
        if features is None:
            raise ValueError("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")

        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        features_scaled = self.feature_scaler.transform(features.reshape(1, -1))

        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        prediction = self.model.predict(features_scaled, verbose=0)[0][0]

        # –¢–µ–∫—É—â–∞—è —Ü–µ–Ω–∞
        current_price = data['close'].iloc[current_index]
        
        # –î–Ω–µ–≤–Ω–æ–π ATRI
        daily_atri = data['atri'].iloc[current_index]

        if self.prediction_type == 'price':
            # –û–±—Ä–∞—Ç–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è —Ü–µ–Ω—ã
            prediction_scaled = self.price_scaler.inverse_transform([[prediction]])
            predicted_price = prediction_scaled[0][0]
            predicted_change = (predicted_price - current_price) / current_price
        else:
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è
            predicted_change = prediction
            predicted_price = current_price * (1 + predicted_change)

        # –ê–Ω–∞–ª–∏–∑ —É—Ä–æ–≤–Ω–µ–π –¥–ª—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏
        strongest_levels = self.days_level.get_strongest_levels(timeframes=['1H', '4H', '1D'], top_n=10)
        level_info = self._calculate_distance_to_levels(current_price, strongest_levels)
        volatility_info = self._calculate_volatility_features(data.iloc[current_index-10:current_index+1])

        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–æ—Ä–≥–æ–≤—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤
        trading_signals = self.signal_generator.calculate_entry_exit_points(
            current_price, predicted_price, daily_atri, level_info
        )

        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
        strategy = self._determine_strategy(current_price, predicted_price, level_info, volatility_info)

        return {
            'current_price': current_price,
            'predicted_price': predicted_price,
            'predicted_change': predicted_change,
            'predicted_change_percent': predicted_change * 100,
            'strategy': strategy,
            'level_info': level_info,
            'volatility_info': volatility_info,
            'confidence': self._calculate_confidence(features_scaled),
            'trading_signals': trading_signals,
            'daily_atri': daily_atri
        }

    def _determine_strategy(self, current_price: float, predicted_price: float,
                          level_info: Dict, volatility_info: Dict) -> str:
        """
        –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–æ—Ä–≥–æ–≤–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è

        Args:
            current_price: —Ç–µ–∫—É—â–∞—è —Ü–µ–Ω–∞
            predicted_price: –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è —Ü–µ–Ω–∞
            level_info: –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± —É—Ä–æ–≤–Ω—è—Ö
            volatility_info: –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏

        Returns:
            —Å—Ç—Ä–æ–∫–∞ —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
        """
        price_change = predicted_price - current_price

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –±–ª–∏–∑–æ—Å—Ç—å –∫ —É—Ä–æ–≤–Ω—è–º
        near_support = level_info['nearest_support_dist'] < 0.02  # –í –ø—Ä–µ–¥–µ–ª–∞—Ö 2%
        near_resistance = level_info['nearest_resistance_dist'] < 0.02
        near_mirror = level_info['nearest_mirror_dist'] < 0.02

        # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 1: –û—Ç–±–æ–π –æ—Ç —Å–∏–ª—å–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è
        if near_support and level_info['nearest_support_strength'] > 5:
            if price_change > 0:
                return "–û—Ç–±–æ–π –æ—Ç —Å–∏–ª—å–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏ - –ø–æ–∫—É–ø–∫–∞"
            else:
                return "–í–æ–∑–º–æ–∂–Ω—ã–π –ø—Ä–æ–±–æ–π —É—Ä–æ–≤–Ω—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏ - –ø—Ä–æ–¥–∞–∂–∞"

        if near_resistance and level_info['nearest_resistance_strength'] > 5:
            if price_change < 0:
                return "–û—Ç–±–æ–π –æ—Ç —Å–∏–ª—å–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è —Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏—è - –ø—Ä–æ–¥–∞–∂–∞"
            else:
                return "–í–æ–∑–º–æ–∂–Ω—ã–π –ø—Ä–æ–±–æ–π —É—Ä–æ–≤–Ω—è —Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏—è - –ø–æ–∫—É–ø–∫–∞"

        # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 2: –ü—Ä–æ–±–æ–π —É—Ä–æ–≤–Ω—è –ø—Ä–∏ –Ω–∏–∑–∫–æ–π –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
        if volatility_info['is_accumulation']:
            if price_change > 0 and near_resistance:
                return "–ü—Ä–æ–±–æ–π —Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏—è –ø—Ä–∏ –Ω–∏–∑–∫–æ–π –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ - –ø–æ–∫—É–ø–∫–∞"
            elif price_change < 0 and near_support:
                return "–ü—Ä–æ–±–æ–π –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –ø—Ä–∏ –Ω–∏–∑–∫–æ–π –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ - –ø—Ä–æ–¥–∞–∂–∞"

        # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 3: –ó–µ—Ä–∫–∞–ª—å–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å
        if near_mirror and level_info['nearest_mirror_strength'] > 3:
            mirror_distance = level_info['nearest_mirror_dist'] * current_price
            if price_change > 0:
                return f"–û—Ç—Ä–∞–±–æ—Ç–∫–∞ –∑–µ—Ä–∫–∞–ª—å–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è –≤–≤–µ—Ä—Ö - —Ü–µ–ª—å +{mirror_distance:.2f}"
            else:
                return f"–û—Ç—Ä–∞–±–æ—Ç–∫–∞ –∑–µ—Ä–∫–∞–ª—å–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è –≤–Ω–∏–∑ - —Ü–µ–ª—å -{mirror_distance:.2f}"

        # –û–±—â–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è
        if abs(price_change) > 0.02:  # –ó–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ –¥–≤–∏–∂–µ–Ω–∏–µ > 2%
            direction = "–ø–æ–∫—É–ø–∫–∞" if price_change > 0 else "–ø—Ä–æ–¥–∞–∂–∞"
            return f"–ó–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ –¥–≤–∏–∂–µ–Ω–∏–µ - {direction}"

        return "–ë–æ–∫–æ–≤–æ–µ –¥–≤–∏–∂–µ–Ω–∏–µ - –æ–∂–∏–¥–∞–Ω–∏–µ"

    def _calculate_confidence(self, features_scaled: np.ndarray) -> float:
        """
        –†–∞—Å—á–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –≤ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏ (–ø—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞)

        Args:
            features_scaled: –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏

        Returns:
            —É—Ä–æ–≤–µ–Ω—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –æ—Ç 0 –¥–æ 1
        """
        # –î–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—Ä–∞—Ç–Ω—É—é –¥–∏—Å–ø–µ—Ä—Å–∏—é –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        feature_variance = np.var(features_scaled)
        confidence = 1 / (1 + feature_variance)

        return min(max(confidence, 0.1), 0.9)  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –æ—Ç 0.1 –¥–æ 0.9

    def evaluate_model(self):
        """–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏"""
        if self.model is None:
            print("‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞!")
            return None

        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ
        y_pred = self.model.predict(self.X_test)
        y_test = self.y_test

        # –û–±—Ä–∞—Ç–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–æ–ª—å–∫–æ –¥–ª—è —Ü–µ–Ω—ã
        if self.prediction_type == 'price':
            y_test_original = self.price_scaler.inverse_transform(y_test)
            y_pred_original = self.price_scaler.inverse_transform(y_pred)
        else:
            y_test_original = y_test
            y_pred_original = y_pred

        # –ú–µ—Ç—Ä–∏–∫–∏
        mse = mean_squared_error(y_test_original, y_pred_original)
        mae = mean_absolute_error(y_test_original, y_pred_original)
        r2 = r2_score(y_test_original, y_pred_original)

        print("üìà –û–¶–ï–ù–ö–ê –ú–û–î–ï–õ–ò:")
        print(f"MSE: {mse:.6f}")
        print(f"MAE: {mae:.6f}")
        print(f"R¬≤: {r2:.4f}")

        # –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ—Å—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
        if self.prediction_type == 'change':
            actual_directions = np.sign(y_test_original.flatten())
            pred_directions = np.sign(y_pred_original.flatten())
            direction_accuracy = np.mean(actual_directions == pred_directions)
            print(f"–¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è: {direction_accuracy:.4f}")

        return {
            'mse': mse,
            'mae': mae,
            'r2': r2,
            'y_test': y_test_original,
            'y_pred': y_pred_original
        }

    def generate_trading_report(self, data: pd.DataFrame, last_n_predictions: int = 10) -> Dict:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –ø–æ —Ç–æ—Ä–≥–æ–≤—ã–º —Å–∏–≥–Ω–∞–ª–∞–º –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
        
        Args:
            data: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
            last_n_predictions: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            dict —Å –æ—Ç—á–µ—Ç–æ–º –ø–æ —Ç–æ—Ä–≥–æ–≤—ã–º —Å–∏–≥–Ω–∞–ª–∞–º
        """
        if not self.is_trained:
            raise ValueError("–ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞")
        
        signals = []
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–∏–≥–Ω–∞–ª—ã –¥–ª—è –ø–æ—Å–ª–µ–¥–Ω–∏—Ö N –ø–µ—Ä–∏–æ–¥–æ–≤
        start_idx = max(self.lookback_period, len(data) - last_n_predictions)
        
        for i in range(start_idx, len(data)):
            try:
                prediction_result = self.predict_with_trading_signals(data, i)
                prediction_result['timestamp'] = data.index[i] if hasattr(data, 'index') else i
                # When passing to rank_signals, we need the actual trading_signals dict
                # not the whole prediction_result if rank_signals expects 'hot_deals' at top level
                # As per previous fix, we need to pass the trading_signals part.
                
                # Make a copy to avoid modifying the original prediction_result if needed elsewhere
                signal_for_ranking = prediction_result['trading_signals'].copy() 
                signal_for_ranking['timestamp'] = prediction_result['timestamp'] # Add timestamp to it
                signals.append(signal_for_ranking) # Append the correct dict for ranking
                
            except Exception as e: # Catch specific exceptions or just general for debugging
                # Print the error for debugging, but continue
                print(f"Error generating signal for index {i}: {e}")
                continue
        
        # –†–∞–Ω–∂–∏—Ä—É–µ–º —Å–∏–≥–Ω–∞–ª—ã
        ranked_signals = self.signal_generator.rank_signals(signals)
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≥–æ—Ä—è—á–∏–µ —Å–¥–µ–ª–∫–∏
        hot_deals_summary = {}
        total_hot_deals = 0
        
        for signal in ranked_signals: # 'signal' here is now the 'trading_signals' dict
            # Make sure 'hot_deals' exists, it might be empty
            hot_deals = signal.get('hot_deals', []) # Use .get with a default empty list
            total_hot_deals += len(hot_deals)
            
            for deal in hot_deals:
                rr_ratio = deal['rr_ratio']
                if rr_ratio not in hot_deals_summary:
                    hot_deals_summary[rr_ratio] = {
                        'count': 0,
                        'avg_probability': 0,
                        'total_profit_potential': 0
                    }
                
                hot_deals_summary[rr_ratio]['count'] += 1
                hot_deals_summary[rr_ratio]['avg_probability'] += deal['probability']
                hot_deals_summary[rr_ratio]['total_profit_potential'] += deal['profit_potential']
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è
        for rr_ratio in hot_deals_summary:
            count = hot_deals_summary[rr_ratio]['count']
            if count > 0: # Avoid division by zero
                hot_deals_summary[rr_ratio]['avg_probability'] /= count
        
        return {
            'total_signals': len(signals),
            'ranked_signals': ranked_signals,
            'hot_deals_summary': hot_deals_summary,
            'total_hot_deals': total_hot_deals,
            'avg_score': np.mean([s['score'] for s in ranked_signals]) if ranked_signals else 0
        }

    #–û—Ç—á–µ—Ç
    def print_trading_report(self, data: pd.DataFrame, last_n_predictions: int = 10):
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∏ –ø–µ—á–∞—Ç–∞–µ—Ç –æ—Ç—á–µ—Ç –ø–æ —Ç–æ—Ä–≥–æ–≤—ã–º —Å–∏–≥–Ω–∞–ª–∞–º.
        
        Args:
            data: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
            last_n_predictions: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        """
        report = self.generate_trading_report(data, last_n_predictions)

        print("\n--- Trading Report ---")
        print(f"Total Signals Generated: {report['total_signals']}")
        print(f"Average Signal Score: {report['avg_score']:.2f}")

        print("\n--- Ranked Signals (Top 5) ---")
        # Ensure 'ranked_signals' exists and is iterable
        if 'ranked_signals' in report and report['ranked_signals']:
            for i, signal in enumerate(report['ranked_signals'][:5]):
                print(f"  Signal {i+1} (Score: {signal.get('score', 0):.2f}):")
                print(f"    Timestamp: {signal.get('timestamp', 'N/A')}")
                # Accessing directly from 'signal' now, since it's the trading_signals dict
                print(f"    Direction: {signal.get('direction', 'N/A')}")
                print(f"    Entry Price: {signal.get('entry_price', 'N/A'):.4f}")
                print(f"    Stop Loss: {signal.get('stop_loss', 'N/A'):.4f}")
                print(f"    Risk: {signal.get('risk', 'N/A'):.4f}")
                
                hot_deals = signal.get('hot_deals', [])
                if hot_deals:
                    print("    Hot Deals:")
                    for deal in hot_deals:
                        print(f"      - TP Level: {deal.get('tp_level', 'N/A')}, R/R: {deal.get('rr_ratio', 'N/A'):.2f}, Probability: {deal.get('probability', 'N/A'):.2f}, Profit Potential: {deal.get('profit_potential', 'N/A'):.4f}")
                else:
                    print("    No Hot Deals found for this signal.")
        else:
            print("  No ranked signals to display.")

        print("\n--- Hot Deals Summary ---")
        if 'hot_deals_summary' in report and report['hot_deals_summary']:
            for rr_ratio, summary in sorted(report['hot_deals_summary'].items()):
                print(f"  R/R Ratio {rr_ratio}:")
                print(f"    Count: {summary.get('count', 0)}")
                print(f"    Average Probability: {summary.get('avg_probability', 0):.2f}")
                print(f"    Total Profit Potential: {summary.get('total_profit_potential', 0):.4f}")
        else:
            print("  No hot deals summary to display.")

        print(f"\nTotal Hot Deals Identified: {report.get('total_hot_deals', 0)}")    

    def plot_trading_signals(self, data: pd.DataFrame, last_n_days: int = 30):
        """
        –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ç–æ—Ä–≥–æ–≤—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤ –Ω–∞ –≥—Ä–∞—Ñ–∏–∫–µ —Ü–µ–Ω—ã
        
        Args:
            data: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
            last_n_days: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –¥–Ω–µ–π –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
        """
        if not self.is_trained:
            print("‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞!")
            return
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –¥–Ω–µ–π
        plot_data = data.iloc[-last_n_days:].copy()
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–∏–≥–Ω–∞–ª—ã
        signals = []
        signal_indices = []
        
        for i in range(len(plot_data)):
            try:
                idx = len(data) - last_n_days + i
                if idx >= self.lookback_period:
                    signal = self.predict_with_trading_signals(data, idx)
                    signals.append(signal)
                    signal_indices.append(i)
            except:
                continue
        
        # –°–æ–∑–¥–∞–µ–º –≥—Ä–∞—Ñ–∏–∫
        fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(15, 12))
        
        # –ì—Ä–∞—Ñ–∏–∫ —Ü–µ–Ω—ã —Å —Å–∏–≥–Ω–∞–ª–∞–º–∏
        ax1.plot(plot_data.index, plot_data['close'], label='–¶–µ–Ω–∞ –∑–∞–∫—Ä—ã—Ç–∏—è', linewidth=2)
        
        # –û—Ç–º–µ—á–∞–µ–º —Ç–æ—á–∫–∏ –≤—Ö–æ–¥–∞
        for i, signal in enumerate(signals):
            idx = signal_indices[i]
            trading_signal = signal['trading_signals']
            
            if trading_signal['direction'] == 'LONG':
                ax1.scatter(plot_data.index[idx], signal['current_price'], 
                           color='green', marker='^', s=100, alpha=0.7)
                # –°—Ç–æ–ø-–ª–æ—Å—Å
                ax1.scatter(plot_data.index[idx], trading_signal['stop_loss'], 
                           color='red', marker='v', s=50, alpha=0.7)
            else:
                ax1.scatter(plot_data.index[idx], signal['current_price'], 
                           color='red', marker='v', s=100, alpha=0.7)
                # –°—Ç–æ–ø-–ª–æ—Å—Å
                ax1.scatter(plot_data.index[idx], trading_signal['stop_loss'], 
                           color='green', marker='^', s=50, alpha=0.7)
        
        ax1.set_title('–¢–æ—Ä–≥–æ–≤—ã–µ —Å–∏–≥–Ω–∞–ª—ã –Ω–∞ –≥—Ä–∞—Ñ–∏–∫–µ —Ü–µ–Ω—ã')
        ax1.set_ylabel('–¶–µ–Ω–∞ USD')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # –ì—Ä–∞—Ñ–∏–∫ ATRI
        ax2.plot(plot_data.index, plot_data['atri'], label='ATRI', color='orange')
        ax2.set_title('–î–Ω–µ–≤–Ω–æ–π ATRI')
        ax2.set_ylabel('ATRI')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        # –ì—Ä–∞—Ñ–∏–∫ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è R/R –¥–ª—è –≥–æ—Ä—è—á–∏—Ö —Å–¥–µ–ª–æ–∫
        hot_deals_data = []
        timestamps = []
        
        for i, signal in enumerate(signals):
            hot_deals = signal['trading_signals']['hot_deals']
            timestamp = plot_data.index[signal_indices[i]]
            
            if hot_deals:
                max_rr = max(deal['rr_ratio'] for deal in hot_deals)
                hot_deals_data.append(max_rr)
                timestamps.append(timestamp)
            else:
                hot_deals_data.append(0)
                timestamps.append(timestamp)
        
        ax3.bar(timestamps, hot_deals_data, alpha=0.7, color='purple')
        ax3.set_title('–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ R/R –¥–ª—è –≥–æ—Ä—è—á–∏—Ö —Å–¥–µ–ª–æ–∫')
        ax3.set_ylabel('R/R Ratio')
        ax3.axhline(y=3, color='red', linestyle='--', alpha=0.7, label='–ú–∏–Ω–∏–º—É–º –¥–ª—è –≥–æ—Ä—è—á–∏—Ö —Å–¥–µ–ª–æ–∫')
        ax3.legend()
        ax3.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()
        
        return fig

    def plot_training_history(self):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∏—Å—Ç–æ—Ä–∏–∏ –æ–±—É—á–µ–Ω–∏—è"""
        if self.training_history is None:
            print("–ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞")
            return

        plt.figure(figsize=(12, 4))

        # –ì—Ä–∞—Ñ–∏–∫ –ø–æ—Ç–µ—Ä—å
        plt.subplot(1, 2, 1)
        plt.plot(self.training_history.history['loss'], label='Training Loss')
        plt.plot(self.training_history.history['val_loss'], label='Validation Loss')
        plt.title('Model Loss')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.legend()

        # –ì—Ä–∞—Ñ–∏–∫ MAE
        plt.subplot(1, 2, 2)
        plt.plot(self.training_history.history['mae'], label='Training MAE')
        plt.plot(self.training_history.history['val_mae'], label='Validation MAE')
        plt.title('Model MAE')
        plt.xlabel('Epoch')
        plt.ylabel('MAE')
        plt.legend()

        plt.tight_layout()
        plt.show()

    def plot_predictions(self, n_samples=100):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π"""
        if self.model is None:
            print("‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞!")
            return

        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        eval_results = self.evaluate_model()
        y_test = eval_results['y_test'][:n_samples]
        y_pred = eval_results['y_pred'][:n_samples]

        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 10))

        # –ì—Ä–∞—Ñ–∏–∫ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
        ax1.plot(y_test.flatten(), label='Actual', alpha=0.7)
        ax1.plot(y_pred.flatten(), label='Predicted', alpha=0.7)
        ax1.set_title(f'–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –∏ —Ä–µ–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π (–ø–µ—Ä–≤—ã–µ {n_samples} —Ç–æ—á–µ–∫)')
        ax1.set_xlabel('–í—Ä–µ–º—è')
        ax1.set_ylabel('–¶–µ–Ω–∞')
        ax1.legend()
        ax1.grid(True)

        # –ì—Ä–∞—Ñ–∏–∫ –æ—à–∏–±–æ–∫
        errors = y_test.flatten() - y_pred.flatten()
        ax2.plot(errors, color='red', alpha=0.7)
        ax2.axhline(y=0, color='black', linestyle='--')
        ax2.set_title('–û—à–∏–±–∫–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π')
        ax2.set_xlabel('–í—Ä–µ–º—è')
        ax2.set_ylabel('–û—à–∏–±–∫–∞')
        ax2.grid(True)

        plt.tight_layout()
        return fig

    def save_model_auto(self):
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å –≤—Ä–µ–º–µ–Ω–Ω–æ–π –º–µ—Ç–∫–æ–π"""
        if self.model is None:
            raise ValueError("–ú–æ–¥–µ–ª—å –Ω–µ —Å–æ–∑–¥–∞–Ω–∞")
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        model_name = f"crypto_model_{timestamp}"
        
        self.save_model(model_name)

    def save_model(self, model_name: str):
        """
        –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∏ –≤—Å–µ—Ö —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        
        Args:
            model_name: –∏–º—è –º–æ–¥–µ–ª–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        """
        if self.model is None:
            raise ValueError("–ú–æ–¥–µ–ª—å –Ω–µ —Å–æ–∑–¥–∞–Ω–∞")

        model_dir = os.path.join(self.model_save_dir, model_name)
        os.makedirs(model_dir, exist_ok=True)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º Keras –º–æ–¥–µ–ª—å
        keras_path = os.path.join(model_dir, "keras_model.h5")
        self.model.save(keras_path)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–∫–µ–π–ª–µ—Ä—ã
        scalers_path = os.path.join(model_dir, "scalers.pkl")
        scalers_data = {
            'price_scaler': self.price_scaler,
            'feature_scaler': self.feature_scaler
        }
        with open(scalers_path, 'wb') as f:
            pickle.dump(scalers_data, f)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏
        params_path = os.path.join(model_dir, "model_params.pkl")
        model_params = {
            'lookback_period': self.lookback_period,
            'prediction_horizon': self.prediction_horizon,
            'prediction_type': self.prediction_type,
            'is_trained': self.is_trained
        }
        with open(params_path, 'wb') as f:
            pickle.dump(model_params, f)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ç–æ—Ä–∏—é –æ–±—É—á–µ–Ω–∏—è (–µ—Å–ª–∏ –µ—Å—Ç—å)
        if self.training_history is not None:
            history_path = os.path.join(model_dir, "training_history.pkl")
            with open(history_path, 'wb') as f:
                pickle.dump(self.training_history.history, f)

        print(f"‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {model_dir}")
        return model_dir

    def load_model(self, model_name: str):
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏ –≤—Å–µ—Ö —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        
        Args:
            model_name: –∏–º—è –º–æ–¥–µ–ª–∏ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏
        """
        model_dir = os.path.join(self.model_save_dir, model_name)
        
        if not os.path.exists(model_dir):
            raise ValueError(f"–ú–æ–¥–µ–ª—å {model_name} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ {self.model_save_dir}")

        # –ó–∞–≥—Ä—É–∂–∞–µ–º Keras –º–æ–¥–µ–ª—å
        keras_path = os.path.join(model_dir, "keras_model.h5")
        self.model = keras.models.load_model(keras_path)

        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–∫–µ–π–ª–µ—Ä—ã
        scalers_path = os.path.join(model_dir, "scalers.pkl")
        with open(scalers_path, 'rb') as f:
            scalers_data = pickle.load(f)
            self.price_scaler = scalers_data['price_scaler']
            self.feature_scaler = scalers_data['feature_scaler']

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏
        params_path = os.path.join(model_dir, "model_params.pkl")
        with open(params_path, 'rb') as f:
            model_params = pickle.load(f)
            self.lookback_period = model_params['lookback_period']
            self.prediction_horizon = model_params['prediction_horizon']
            self.prediction_type = model_params['prediction_type']
            self.is_trained = model_params['is_trained']

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –æ–±—É—á–µ–Ω–∏—è (–µ—Å–ª–∏ –µ—Å—Ç—å)
        history_path = os.path.join(model_dir, "training_history.pkl")
        if os.path.exists(history_path):
            with open(history_path, 'rb') as f:
                history_dict = pickle.load(f)
                # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç –∏—Å—Ç–æ—Ä–∏–∏ (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)
                class HistoryWrapper:
                    def __init__(self, history_dict):
                        self.history = history_dict
                self.training_history = HistoryWrapper(history_dict)

        print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ {model_dir}")

    def list_saved_models(self) -> List[str]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
        
        Returns:
            —Å–ø–∏—Å–æ–∫ –∏–º–µ–Ω —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
        """
        if not os.path.exists(self.model_save_dir):
            return []
        
        models = []
        for item in os.listdir(self.model_save_dir):
            model_path = os.path.join(self.model_save_dir, item)
            if os.path.isdir(model_path):
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
                required_files = ["keras_model.h5", "scalers.pkl", "model_params.pkl"]
                if all(os.path.exists(os.path.join(model_path, f)) for f in required_files):
                    models.append(item)
        
        return sorted(models)

    def generate_trading_report(self, data: pd.DataFrame, last_n_predictions: int = 10) -> Dict:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –ø–æ —Ç–æ—Ä–≥–æ–≤—ã–º —Å–∏–≥–Ω–∞–ª–∞–º –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
        
        Args:
            data: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
            last_n_predictions: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            dict —Å –æ—Ç—á–µ—Ç–æ–º –ø–æ —Ç–æ—Ä–≥–æ–≤—ã–º —Å–∏–≥–Ω–∞–ª–∞–º
        """
        if not self.is_trained:
            raise ValueError("–ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞")
        
        signals_for_ranking = [] # This will store the actual trading_signals dictionaries
        all_prediction_results = [] # Keep this if you need the full results for other parts

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–∏–≥–Ω–∞–ª—ã –¥–ª—è –ø–æ—Å–ª–µ–¥–Ω–∏—Ö N –ø–µ—Ä–∏–æ–¥–æ–≤
        start_idx = max(self.lookback_period, len(data) - last_n_predictions)
        
        for i in range(start_idx, len(data)):
            try:
                prediction_result = self.predict_with_trading_signals(data, i)
                # Ensure the timestamp is added to the full result if needed elsewhere
                prediction_result['timestamp'] = data.index[i] if hasattr(data, 'index') else i
                all_prediction_results.append(prediction_result)

                # Extract the 'trading_signals' part and add timestamp to it for ranking if needed
                # The rank_signals function seems to expect 'hot_deals' directly,
                # so we should pass the 'trading_signals' dictionary.
                trading_signal_data = prediction_result['trading_signals']
                trading_signal_data['timestamp'] = prediction_result['timestamp'] # Add timestamp to the signal data
                trading_signal_data['score'] = 0 # Initialize score, will be updated by rank_signals
                signals_for_ranking.append(trading_signal_data)

            except Exception as e: # Catch specific exceptions or just general for debugging
                print(f"Error generating signal for index {i}: {e}")
                continue
        
        # –†–∞–Ω–∂–∏—Ä—É–µ–º —Å–∏–≥–Ω–∞–ª—ã. Now signals_for_ranking contains dictionaries directly consumable by rank_signals
        ranked_signals = self.signal_generator.rank_signals(signals_for_ranking)
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≥–æ—Ä—è—á–∏–µ —Å–¥–µ–ª–∫–∏
        hot_deals_summary = {}
        total_hot_deals = 0
        
        for signal in ranked_signals: # These are the 'trading_signals' dicts from before
            hot_deals = signal['hot_deals'] # Now 'hot_deals' is directly accessible
            total_hot_deals += len(hot_deals)
            
            for deal in hot_deals:
                rr_ratio = deal['rr_ratio']
                if rr_ratio not in hot_deals_summary:
                    hot_deals_summary[rr_ratio] = {
                        'count': 0,
                        'avg_probability': 0,
                        'total_profit_potential': 0
                    }
                
                hot_deals_summary[rr_ratio]['count'] += 1
                hot_deals_summary[rr_ratio]['avg_probability'] += deal['probability']
                hot_deals_summary[rr_ratio]['total_profit_potential'] += deal['profit_potential']
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è
        for rr_ratio in hot_deals_summary:
            count = hot_deals_summary[rr_ratio]['count']
            if count > 0: # Avoid division by zero
                hot_deals_summary[rr_ratio]['avg_probability'] /= count
            
        return {
            'total_signals': len(signals_for_ranking), # Use the count of signals actually ranked
            'ranked_signals': ranked_signals,
            'hot_deals_summary': hot_deals_summary,
            'total_hot_deals': total_hot_deals,
            'avg_score': np.mean([s['score'] for s in ranked_signals]) if ranked_signals else 0
        }


# == –ó–∞–º–µ–Ω–∏—Ç–µ–ª—å DaysLevel –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è ==
class MockDaysLevel:
    def __init__(self, data):
        self.data = data
        self.timeframe = '1D'

    def get_strongest_levels(self, timeframes=None, top_n=10):
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ñ–∏–∫—Ç–∏–≤–Ω—ã–µ —É—Ä–æ–≤–Ω–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –º–∞–∫—Å–∏–º—É–º–æ–≤/–º–∏–Ω–∏–º—É–º–æ–≤
        current_price = self.data['close'].iloc[-1]
        
        # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 50 —Å–≤–µ—á–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        recent_data = self.data.iloc[-50:]
        
        levels = []
        
        # –î–æ–±–∞–≤–ª—è–µ–º —É—Ä–æ–≤–Ω–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–∞–∫—Å–∏–º—É–º–æ–≤ –∏ –º–∏–Ω–∏–º—É–º–æ–≤
        highs = recent_data['high'].rolling(5).max()
        lows = recent_data['low'].rolling(5).min()
        
        # –ù–∞—Ö–æ–¥–∏–º –∑–Ω–∞—á–∏–º—ã–µ —É—Ä–æ–≤–Ω–∏
        for i in range(len(recent_data)):
            if i < 2 or i >= len(recent_data) - 2:
                continue
                
            price = recent_data['close'].iloc[i]
            high = recent_data['high'].iloc[i]
            low = recent_data['low'].iloc[i]
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ –ª–æ–∫–∞–ª—å–Ω—ã–º –º–∞–∫—Å–∏–º—É–º–æ–º/–º–∏–Ω–∏–º—É–º–æ–º
            is_high = (high >= recent_data['high'].iloc[i-2:i+3].max())
            is_low = (low <= recent_data['low'].iloc[i-2:i+3].min())
            
            if is_high:
                strength = np.random.uniform(3, 8)
                levels.append((
                    recent_data.index[i],
                    high,
                    strength,
                    '1H',
                    'resistance',
                    'up'
                ))
            
            if is_low:
                strength = np.random.uniform(3, 8)
                levels.append((
                    recent_data.index[i],
                    low,
                    strength,
                    '1H',
                    'support',
                    'down'
                ))
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∑–µ—Ä–∫–∞–ª—å–Ω—ã–µ —É—Ä–æ–≤–Ω–∏
        for _ in range(3):
            level = current_price * (1 + np.random.normal(0, 0.03))
            strength = np.random.uniform(4, 7)
            levels.append((
                recent_data.index[-1],
                level,
                strength,
                '4H',
                'mirror',
                'neutral'
            ))
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Å–∏–ª–µ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ø N
        levels.sort(key=lambda x: x[2], reverse=True)
        return levels[:top_n]


# == –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —É–ª—É—á—à–µ–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã ==
def example_usage():
    """
    –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —É–ª—É—á—à–µ–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Ü–µ–Ω—ã —Å —Ç–æ—Ä–≥–æ–≤—ã–º–∏ —Å–∏–≥–Ω–∞–ª–∞–º–∏
    """
    print("üöÄ –ó–∞–ø—É—Å–∫ —É–ª—É—á—à–µ–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã —Ç–æ—Ä–≥–æ–≤—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤...")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö (–∑–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ –≤–∞—à –ø—É—Ç—å)
    csv_file_path = '/mnt/c/Users/ecopa/Desktop/Proekts/Trader bot/kandles.csv'
    
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        def load_data_from_csv(csv_file_path, start_date=None, end_date=None):
            data = pd.read_csv(csv_file_path, parse_dates=['open_time'])
            data.rename(columns={'open_time': 'Date', 'close': 'Close'}, inplace=True)
            data.sort_values('Date', inplace=True)
            
            if start_date:
                data = data[data['Date'] >= pd.to_datetime(start_date)]
            if end_date:
                data = data[data['Date'] <= pd.to_datetime(end_date)]
            
            return data
        
        df = load_data_from_csv(csv_file_path, start_date='2024-11-01', end_date='2025-06-05')
        data = df.copy()
        
    except:
        print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ, —Å–æ–∑–¥–∞–µ–º —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ...")
        # –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        np.random.seed(42)
        dates = pd.date_range('2024-01-01', periods=1000, freq='1D')

        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö OHLC –¥–∞–Ω–Ω—ã—Ö
        price = 45000  # –ù–∞—á–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞ BTC
        prices = [price]

        for i in range(999):
            change = np.random.normal(0, 0.025)  # 2.5% —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ
            price *= (1 + change)
            prices.append(price)

        # –°–æ–∑–¥–∞–Ω–∏–µ OHLC –¥–∞–Ω–Ω—ã—Ö
        data = pd.DataFrame(index=dates)
        data['close'] = prices
        data['open'] = data['close'].shift(1) * (1 + np.random.normal(0, 0.005, len(data)))
        data['high'] = np.maximum(data['open'], data['close']) * (1 + np.abs(np.random.normal(0, 0.015, len(data))))
        data['low'] = np.minimum(data['open'], data['close']) * (1 - np.abs(np.random.normal(0, 0.015, len(data))))
        data['volume'] = np.random.uniform(1000, 10000, len(data))
        data = data.dropna()

    # –î–æ–±–∞–≤–ª—è–µ–º ATRI (Average True Range Index)
    def calculate_atri(data, period=14):
        high_low = data['high'] - data['low']
        high_close_prev = np.abs(data['high'] - data['close'].shift(1))
        low_close_prev = np.abs(data['low'] - data['close'].shift(1))
        
        true_range = np.maximum(high_low, np.maximum(high_close_prev, low_close_prev))
        atri = true_range.rolling(window=period).mean()
        
        return atri
    
    data['atri'] = calculate_atri(data)
    data = data.dropna()

    print(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(data)} –∑–∞–ø–∏—Å–µ–π –¥–∞–Ω–Ω—ã—Ö")

    # –°–æ–∑–¥–∞–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ —É—Ä–æ–≤–Ω–µ–π
    days_level = MockDaysLevel(data)

    print("üß† –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è...")
    predictor = CriptoPredictionNN(
        days_level=days_level,
        lookback_period=30,
        prediction_horizon=5,
        prediction_type='price',
        model_save_dir='crypto_models'
    )

    print("üìö –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
    try:
        history = predictor.train(data, epochs=100, batch_size=32, verbose=1)

        print("\nüîÆ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–æ—Ä–≥–æ–≤—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤...")
        
        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å —Ç–æ—Ä–≥–æ–≤—ã–º–∏ —Å–∏–≥–Ω–∞–ª–∞–º–∏
        prediction = predictor.predict_with_trading_signals(data)

        print("\n" + "="*70)
        print("üìà –†–ï–ó–£–õ–¨–¢–ê–¢ –ê–ù–ê–õ–ò–ó–ê")
        print("="*70)
        print(f"üí∞ –¢–µ–∫—É—â–∞—è —Ü–µ–Ω–∞: ${prediction['current_price']:.2f}")
        print(f"üéØ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è —Ü–µ–Ω–∞: ${prediction['predicted_price']:.2f}")
        print(f"üìä –û–∂–∏–¥–∞–µ–º–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ: {prediction['predicted_change_percent']:.2f}%")
        print(f"üìã –°—Ç—Ä–∞—Ç–µ–≥–∏—è: {prediction['strategy']}")
        print(f"üé≤ –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {prediction['confidence']:.2f}")
        print(f"üìè –î–Ω–µ–≤–Ω–æ–π ATRI: ${prediction['daily_atri']:.2f}")

        # –¢–æ—Ä–≥–æ–≤—ã–µ —Å–∏–≥–Ω–∞–ª—ã
        ts = prediction['trading_signals']
        print(f"\nüéØ –¢–û–†–ì–û–í–´–ï –°–ò–ì–ù–ê–õ–´:")
        print(f"   –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ: {ts['direction']}")
        print(f"   –¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞: ${ts['entry_price']:.2f}")
        print(f"   –°—Ç–æ–ø-–ª–æ—Å—Å: ${ts['stop_loss']:.2f}")
        print(f"   –†–∏—Å–∫: ${ts['risk']:.2f}")

        print(f"\nüî• –ì–û–†–Ø–ß–ò–ï –°–î–ï–õ–ö–ò (R/R ‚â• 3:1):")
        for i, deal in enumerate(ts['hot_deals'][:5]):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ø-5
            print(f"   {i+1}. {deal['tp_level']}: R/R {deal['rr_ratio']}:1, "
                  f"–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å: {deal['probability']:.2f}, "
                  f"–ø–æ—Ç–µ–Ω—Ü–∏–∞–ª: ${deal['profit_potential']:.2f}")

        print(f"\nüìä –í–°–ï –£–†–û–í–ù–ò –¢–ï–ô–ö-–ü–†–û–§–ò–¢–ê:")
        for tp_name, tp_data in ts['take_profits'].items():
            print(f"   {tp_name}: ${tp_data['price']:.2f} "
                  f"(R/R {tp_data['ratio']}:1, "
                  f"—Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ: {tp_data['distance_atri']:.1f} ATRI, "
                  f"–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å: {tp_data['probability']:.2f})")

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç –ø–æ —Ç–æ—Ä–≥–æ–≤—ã–º —Å–∏–≥–Ω–∞–ª–∞–º
        predictor.print_trading_report(data, last_n_predictions=20)

        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
        print("\nüìä –°–æ–∑–¥–∞–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤...")
        
        # –ò—Å—Ç–æ—Ä–∏—è –æ–±—É—á–µ–Ω–∏—è
        predictor.plot_training_history()
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è vs —Ä–µ–∞–ª—å–Ω–æ—Å—Ç—å
        predictor.plot_predictions(n_samples=200)
        
        # –¢–æ—Ä–≥–æ–≤—ã–µ —Å–∏–≥–Ω–∞–ª—ã –Ω–∞ –≥—Ä–∞—Ñ–∏–∫–µ
        predictor.plot_trading_signals(data, last_n_days=60)

        # –°–ø–∏—Å–æ–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
        saved_models = predictor.list_saved_models()
        print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏: {saved_models}")

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    example_usage()