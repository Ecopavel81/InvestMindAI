import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import matplotlib.pyplot as plt
from typing import List, Tuple, Dict, Optional
import warnings
warnings.filterwarnings('ignore')

# == –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö ==
csv_file_path = '/mnt/c/Users/ecopa/Desktop/Proekts/Trader bot/kandles.csv'
df_raw = pd.read_csv(csv_file_path)
print(df_raw.columns)

Xtrain = pd.read_csv(csv_file_path)
Xtest = pd.read_csv(csv_file_path)

def load_data_from_csv(csv_file_path, start_date=None, end_date=None):
    """
    –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –æ —Ü–µ–Ω–µ BTC –∏–∑ CSV –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –¥–∞—Ç–µ.

    –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
    filepath -- –ø—É—Ç—å –∫ CSV-—Ñ–∞–π–ª—É
    start_date, end_date -- –≥—Ä–∞–Ω–∏—Ü—ã —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ (—Å—Ç—Ä–æ–∫–∏ 'YYYY-MM-DD')
    """
    # –ß–∏—Ç–∞–µ–º open_time –∫–∞–∫ –¥–∞—Ç—É
    data = pd.read_csv(csv_file_path, parse_dates=['open_time'])

    # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º –∫–æ–ª–æ–Ω–∫—É –¥–ª—è –µ–¥–∏–Ω–æ–æ–±—Ä–∞–∑–∏—è
    data.rename(columns={'open_time': 'Date', 'close': 'Close'}, inplace=True)
    data.sort_values('Date', inplace=True)

    # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –¥–∞—Ç–∞–º
    if start_date:
        data = data[data['Date'] >= pd.to_datetime(start_date)]
    if end_date:
        data = data[data['Date'] <= pd.to_datetime(end_date)]

    return data

def visualize_data(data):
    """
    –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö —Ü–µ–Ω BTC.

    –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
    data -- DataFrame —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ Date –∏ Close
    """
    plt.figure(figsize=(14, 6))
    plt.plot(data['Date'], data['Close'], label='–¶–µ–Ω–∞ –∑–∞–∫—Ä—ã—Ç–∏—è')
    plt.title('–ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ —Ü–µ–Ω—ã BTC')
    plt.xlabel('–î–∞—Ç–∞')
    plt.ylabel('–¶–µ–Ω–∞ –≤ USD')
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.show()

df = load_data_from_csv(csv_file_path, start_date='2024-11-01', end_date='2025-06-05')
visualize_data(df)
data = df.copy()


class CriptoPredictionNN:
    """
    –ù–µ–π—Ä–æ—Å–µ—Ç—å –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Ü–µ–Ω—ã –∞–∫—Ç–∏–≤–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ —É—Ä–æ–≤–Ω–µ–π –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –∏ —Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏—è.

    –û—Å–Ω–æ–≤–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏:
    1) –û—Ç–±–æ–π –æ—Ç —Å–∏–ª—å–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è (—Å–≤–µ—Ä—Ö—É –∏–ª–∏ —Å–Ω–∏–∑—É)
    2) –ü—Ä–æ–±–æ–π —É—Ä–æ–≤–Ω—è: –Ω–∞–±–ª—é–¥–∞–µ—Ç—Å—è –Ω–∞–∫–æ–ø–ª–µ–Ω–∏–µ, –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å < 0.5 ATRI
    3) –ó–µ—Ä–∫–∞–ª—å–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å: —Ü–µ–Ω–∞ –ø—Ä–æ–π–¥–µ—Ç —Ç–∞–∫–æ–µ –∂–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ, –∫–∞–∫ –¥–æ –∑–µ—Ä–∫–∞–ª—å–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è
    """

    def __init__(self, days_level, lookback_period=20, prediction_horizon=5,
                 prediction_type='price'):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Ü–µ–Ω—ã

        Args:
            days_level_analyzer: —ç–∫–∑–µ–º–ø–ª—è—Ä –∫–ª–∞—Å—Å–∞ DaysLevel
            lookback_period: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–µ—Ä–∏–æ–¥–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏—Å—Ç–æ—Ä–∏–∏
            prediction_horizon: –≥–æ—Ä–∏–∑–æ–Ω—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–µ—Ä–∏–æ–¥–æ–≤ –≤–ø–µ—Ä–µ–¥)
            prediction_type: —Ç–∏–ø –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è ('price' –∏–ª–∏ 'change')
        """
        self.days_level = days_level
        self.lookback_period = lookback_period
        self.prediction_horizon = prediction_horizon
        self.prediction_type = prediction_type
        self.is_trained = False

        # –°–∫–µ–π–ª–µ—Ä—ã –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö
        self.price_scaler = MinMaxScaler()
        self.feature_scaler = StandardScaler()

        # –ú–æ–¥–µ–ª—å
        self.model = None

        # –ò—Å—Ç–æ—Ä–∏—è –æ–±—É—á–µ–Ω–∏—è
        self.training_history = None

        # –î–∞–Ω–Ω—ã–µ
        self.X_train = None
        self.X_test = None
        self.y_train = None
        self.y_test = None

    def _calculate_distance_to_levels(self, current_price: float, levels: List[Tuple]) -> Dict:
        """
        –†–∞—Å—á–µ—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è –æ—Ç —Ç–µ–∫—É—â–µ–π —Ü–µ–Ω—ã –¥–æ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —É—Ä–æ–≤–Ω–µ–π

        Args:
            current_price: —Ç–µ–∫—É—â–∞—è —Ü–µ–Ω–∞
            levels: —Å–ø–∏—Å–æ–∫ —É—Ä–æ–≤–Ω–µ–π [(date, level, strength, timeframe, type, direction)]

        Returns:
            dict —Å —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è–º–∏ –∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º–∏ —É—Ä–æ–≤–Ω–µ–π
        """
        if not levels:
            return {
                'nearest_support_dist': 0.01,
                'nearest_resistance_dist': 0.01,
                'nearest_support_strength': 5,
                'nearest_resistance_strength': 5,
                'nearest_mirror_dist': 0.02,
                'nearest_mirror_strength': 6,
                'total_levels_above': 3,
                'total_levels_below': 2,
                'weighted_support_strength': 15,
                'weighted_resistance_strength': 12,
            }

        supports = []
        resistances = []
        mirrors = []

        for level_data in levels:
            _, level, strength, timeframe, level_type, direction = level_data

            if level_type == 'mirror':
                mirrors.append((level, strength))
            elif level < current_price:
                supports.append((level, strength))
            else:
                resistances.append((level, strength))

        # –ë–ª–∏–∂–∞–π—à–∏–µ —É—Ä–æ–≤–Ω–∏
        nearest_support = max(supports, key=lambda x: x[0]) if supports else (0, 0)
        nearest_resistance = min(resistances, key=lambda x: x[0]) if resistances else (0, 0)
        nearest_mirror = min(mirrors, key=lambda x: abs(x[0] - current_price)) if mirrors else (0, 0)

        # –†–∞—Å—á–µ—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π
        support_dist = (current_price - nearest_support[0]) / current_price if nearest_support[0] > 0 else 0
        resistance_dist = (nearest_resistance[0] - current_price) / current_price if nearest_resistance[0] > 0 else 0
        mirror_dist = abs(nearest_mirror[0] - current_price) / current_price if nearest_mirror[0] > 0 else 0

        # –í–∑–≤–µ—à–µ–Ω–Ω–∞—è —Å–∏–ª–∞ —É—Ä–æ–≤–Ω–µ–π
        weighted_support = sum(s * (1 / (1 + abs(l - current_price))) for l, s in supports) if supports else 0
        weighted_resistance = sum(s * (1 / (1 + abs(l - current_price))) for l, s in resistances) if resistances else 0

        return {
            'nearest_support_dist': support_dist,
            'nearest_resistance_dist': resistance_dist,
            'nearest_support_strength': nearest_support[1],
            'nearest_resistance_strength': nearest_resistance[1],
            'nearest_mirror_dist': mirror_dist,
            'nearest_mirror_strength': nearest_mirror[1],
            'total_levels_above': len(resistances),
            'total_levels_below': len(supports),
            'weighted_support_strength': weighted_support,
            'weighted_resistance_strength': weighted_resistance
        }

    def _calculate_volatility_features(self, data: pd.DataFrame, window: int = 10) -> Dict:
        """
        –†–∞—Å—á–µ—Ç —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏

        Args:
            data: DataFrame —Å OHLC –¥–∞–Ω–Ω—ã–º–∏
            window: –æ–∫–Ω–æ –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞

        Returns:
            dict —Å —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º–∏ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
        """
        if len(df) < window:
            return {
                'volatility_ratio': 0.03,
                'is_accumulation': False,
                'price_range_ratio': 0.05,
                'volume_trend': 0.01
            }

        # –°—Ä–µ–¥–Ω–∏–π ATRI –∑–∞ –ø–µ—Ä–∏–æ–¥
        avg_atri = df['atri'].rolling(window=window).mean().iloc[-1]
        current_volatility = df['atri'].iloc[-1]

        # –û—Ç–Ω–æ—à–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–π –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ –∫ —Å—Ä–µ–¥–Ω–µ–π
        volatility_ratio = current_volatility / avg_atri if avg_atri > 0 else 0

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–∞–∫–æ–ø–ª–µ–Ω–∏–µ (–≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å < 0.5 ATRI)
        is_accumulation = volatility_ratio < 0.5

        # –î–∏–∞–ø–∞–∑–æ–Ω —Ü–µ–Ω
        price_range = (data['high'].iloc[-1] - data['low'].iloc[-1]) / data['close'].iloc[-1]
        avg_price_range = ((data['high'] - data['low']) / data['close']).rolling(window=window).mean().iloc[-1]
        price_range_ratio = price_range / avg_price_range if avg_price_range > 0 else 0

        # –¢—Ä–µ–Ω–¥ –æ–±—ä–µ–º–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å)
        volume_trend = 0
        if 'volume' in data.columns:
            recent_volume = data['volume'].iloc[-window:].mean()
            prev_volume = data['volume'].iloc[-2*window:-window].mean()
            volume_trend = (recent_volume - prev_volume) / prev_volume if prev_volume > 0 else 0

        return {
            'volatility_ratio': volatility_ratio,
            'is_accumulation': is_accumulation,
            'price_range_ratio': price_range_ratio,
            'volume_trend': volume_trend
        }

    def _create_features(self, data: pd.DataFrame, index: int) -> np.ndarray:
        """
        –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –Ω–µ–π—Ä–æ—Å–µ—Ç–∏

        Args:
            data: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
            index: –∏–Ω–¥–µ–∫—Å —Ç–µ–∫—É—â–µ–π –ø–æ–∑–∏—Ü–∏–∏

        Returns:
            –º–∞—Å—Å–∏–≤ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        """
        if index < self.lookback_period:
            return None

        # –ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ —Ü–µ–Ω—ã
        historical_prices = data['close'].iloc[index-self.lookback_period:index].values
        price_returns = np.diff(historical_prices) / historical_prices[:-1]

        # –¢–µ–∫—É—â–∞—è —Ü–µ–Ω–∞
        current_price = data['close'].iloc[index]

        # –ü–æ–ª—É—á–µ–Ω–∏–µ —É—Ä–æ–≤–Ω–µ–π
        strongest_levels = self.days_level.get_strongest_levels(timeframes=['1H', '4H', '1D'], top_n=20)

        # –†–∞—Å—á–µ—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π –¥–æ —É—Ä–æ–≤–Ω–µ–π
        level_features = self._calculate_distance_to_levels(current_price, strongest_levels)

        # –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
        volatility_features = self._calculate_volatility_features(
            data.iloc[index-self.lookback_period:index+1]
        )

        # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
        rsi = self._calculate_rsi(historical_prices)
        macd, macd_signal = self._calculate_macd(historical_prices)

        # –°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –≤–µ–∫—Ç–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        features = np.concatenate([
            # –ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏
            price_returns,

            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Ü–µ–Ω
            [np.mean(price_returns), np.std(price_returns), np.min(price_returns), np.max(price_returns)],

            # –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ —É—Ä–æ–≤–Ω–µ–π
            [level_features['nearest_support_dist'],
             level_features['nearest_resistance_dist'],
             level_features['nearest_support_strength'],
             level_features['nearest_resistance_strength'],
             level_features['nearest_mirror_dist'],
             level_features['nearest_mirror_strength'],
             level_features['total_levels_above'],
             level_features['total_levels_below'],
             level_features['weighted_support_strength'],
             level_features['weighted_resistance_strength']],

            # –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
            [volatility_features['volatility_ratio'],
             float(volatility_features['is_accumulation']),
             volatility_features['price_range_ratio'],
             volatility_features['volume_trend']],

            # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
            [rsi, macd, macd_signal],

            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
            [current_price / np.mean(historical_prices),  # –û—Ç–Ω–æ—à–µ–Ω–∏–µ –∫ —Å—Ä–µ–¥–Ω–µ–π —Ü–µ–Ω–µ
             (current_price - np.min(historical_prices)) / (np.max(historical_prices) - np.min(historical_prices))]  # –ü–æ–∑–∏—Ü–∏—è –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ
        ])

        return features

    def _calculate_rsi(self, prices: np.ndarray, period: int = 14) -> float:
        """–†–∞—Å—á–µ—Ç RSI"""
        if len(prices) < period + 1:
            return 50.0

        deltas = np.diff(prices)
        gains = np.where(deltas > 0, deltas, 0)
        losses = np.where(deltas < 0, -deltas, 0)

        avg_gain = np.mean(gains[-period:])
        avg_loss = np.mean(losses[-period:])

        if avg_loss == 0:
            return 100.0

        rs = avg_gain / avg_loss
        rsi = 100 - (100 / (1 + rs))

        return rsi

    def _calculate_macd(self, prices: np.ndarray, fast: int = 12, slow: int = 26, signal: int = 9) -> Tuple[float, float]:
        """–†–∞—Å—á–µ—Ç MACD"""
        if len(prices) < slow:
            return 0.0, 0.0

        ema_fast = self._ema(prices, fast)
        ema_slow = self._ema(prices, slow)

        macd = ema_fast - ema_slow

        # –î–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç–æ–µ —Å–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ –≤–º–µ—Å—Ç–æ EMA –¥–ª—è —Å–∏–≥–Ω–∞–ª—å–Ω–æ–π –ª–∏–Ω–∏–∏
        if len(prices) >= slow + signal:
            macd_line = []
            for i in range(slow-1, len(prices)):
                ema_f = self._ema(prices[:i+1], fast)
                ema_s = self._ema(prices[:i+1], slow)
                macd_line.append(ema_f - ema_s)

            macd_signal = np.mean(macd_line[-signal:])
        else:
            macd_signal = 0.0

        return macd, macd_signal

    def _ema(self, prices: np.ndarray, period: int) -> float:
        """–†–∞—Å—á–µ—Ç —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–≥–æ —Å–∫–æ–ª—å–∑—è—â–µ–≥–æ —Å—Ä–µ–¥–Ω–µ–≥–æ"""
        if len(prices) < period:
            return np.mean(prices)

        alpha = 2.0 / (period + 1)
        ema = prices[0]

        for price in prices[1:]:
            ema = alpha * price + (1 - alpha) * ema

        return ema

    def build_features(self, data: pd.DataFrame) -> np.ndarray:
        """
        –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –º–∞—Ç—Ä–∏—Ü—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ _create_features

        Args:
          data: DataFrame —Å OHLCV –¥–∞–Ω–Ω—ã–º–∏

        Returns:
          np.ndarray: –º–∞—Ç—Ä–∏—Ü–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        """
        features = []

        for i in range(len(data)):
            f = self._create_features(data, i)
            if f is not None:
                features.append(f)

        return np.array(features)

    def prepare_data(self, data: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:
        """
        –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è

        Args:
            data: DataFrame —Å OHLC –¥–∞–Ω–Ω—ã–º–∏

        Returns:
            Tuple[X, y] - –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏ —Ü–µ–ª–µ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        """
        prices = data['close'].values.reshape(-1, 1)

        X, y = [], []

        for i in range(self.lookback_period, len(data) - self.prediction_horizon):
            # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è —Ç–µ–∫—É—â–µ–π –ø–æ–∑–∏—Ü–∏–∏
            features = self._create_features(data, i)
            if features is None:
                continue

            # –¶–µ–ª–µ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
            current_price = data['close'].iloc[i]
            future_price = data['close'].iloc[i + self.prediction_horizon]

            if self.prediction_type == 'price':
                target = future_price
            else:  # change
                target = (future_price - current_price) / current_price

            X.append(features)
            y.append(target)

        return np.array(X), np.array(y)

    def create_model(self, input_shape: int) -> keras.Model:
        """
        –°–æ–∑–¥–∞–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –Ω–µ–π—Ä–æ—Å–µ—Ç–∏

        Args:
            input_shape: —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –≤—Ö–æ–¥–Ω–æ–≥–æ –≤–µ–∫—Ç–æ—Ä–∞

        Returns:
            –º–æ–¥–µ–ª—å Keras
        """
        model = keras.Sequential([
            # –í—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π
            layers.Input(shape=(input_shape,)),

            # –ü–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–µ —Å–ª–æ–∏
            layers.Dense(256, activation='relu'),
            layers.BatchNormalization(),
            layers.Dropout(0.3),

            # –°–∫—Ä—ã—Ç—ã–µ —Å–ª–æ–∏
            layers.Dense(128, activation='relu'),
            layers.BatchNormalization(),
            layers.Dropout(0.3),

            layers.Dense(64, activation='relu'),
            layers.BatchNormalization(),
            layers.Dropout(0.2),

            layers.Dense(32, activation='relu'),
            layers.Dropout(0.2),

            layers.Dense(16, activation='relu'),

            # –í—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π - –æ–¥–∏–Ω –≤—ã—Ö–æ–¥ –¥–ª—è –æ–¥–Ω–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            layers.Dense(1, activation='linear')
        ])

        # –ö–æ–º–ø–∏–ª—è—Ü–∏—è –º–æ–¥–µ–ª–∏
        model.compile(
            optimizer=keras.optimizers.Adam(learning_rate=0.001),
            loss='mse',
            metrics=['mae']
        )

        return model

    def train(self, data: pd.DataFrame, epochs: int = 100, batch_size: int = 32,
              validation_split: float = 0.2, verbose: int = 1):
        """
        –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏

        Args:
            data: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
            epochs: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö –æ–±—É—á–µ–Ω–∏—è
            batch_size: —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞
            validation_split: –¥–æ–ª—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
            verbose: —É—Ä–æ–≤–µ–Ω—å –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏ –≤—ã–≤–æ–¥–∞
        """
        print("–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
        X, y = self.prepare_data(data)

        if len(X) == 0:
            raise ValueError("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")

        print(f"–†–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏: {X.shape}")
        print(f"–†–∞–∑–º–µ—Ä —Ü–µ–ª–µ–≤–æ–≥–æ –≤–µ–∫—Ç–æ—Ä–∞: {y.shape}")

        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ü–µ–ª–µ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        if self.prediction_type == 'price':
            y = y.reshape(-1, 1)
            y_scaled = self.price_scaler.fit_transform(y)
        else:
            y_scaled = y.reshape(-1, 1)

        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        X_scaled = self.feature_scaler.fit_transform(X)

        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏
        X_train, X_test, y_train, y_test = train_test_split(
            X_scaled, y_scaled, test_size=0.2, random_state=42, shuffle=False
        )

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∞—Ç—Ä–∏–±—É—Ç—ã
        self.X_train, self.X_test = X_train, X_test
        self.y_train, self.y_test = y_train, y_test

        # –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
        self.model = self.create_model(X.shape[1])

        # Callbacks –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        callbacks = [
            keras.callbacks.EarlyStopping(
                monitor='val_loss',
                patience=20,
                restore_best_weights=True
            ),
            keras.callbacks.ReduceLROnPlateau(
                monitor='val_loss',
                factor=0.5,
                patience=10,
                min_lr=1e-6
            )
        ]

        # –û–±—É—á–µ–Ω–∏–µ
        print("–ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è...")
        self.training_history = self.model.fit(
            X_train, y_train,
            validation_split=validation_split,
            epochs=epochs,
            callbacks=callbacks,
            batch_size=batch_size,
            verbose=verbose
        )

        # –û—Ü–µ–Ω–∫–∞ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ
        test_loss, test_mae = self.model.evaluate(X_test, y_test, verbose=0)
        print(f"\n–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ:")
        print(f"MSE: {test_loss:.6f}")
        print(f"MAE: {test_mae:.6f}")

        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ
        y_pred = self.model.predict(X_test, verbose=0)

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        rmse = np.sqrt(mean_squared_error(y_test, y_pred))
        print(f"RMSE: {rmse:.6f}")

        self.is_trained = True

        return self.training_history

    def evaluate_model(self):
        """–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏"""
        if self.model is None:
            print("‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞!")
            return None

        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ
        y_pred = self.model.predict(self.X_test)
        y_test = self.y_test

        # –û–±—Ä–∞—Ç–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–æ–ª—å–∫–æ –¥–ª—è —Ü–µ–Ω—ã
        if self.prediction_type == 'price':
            y_test_original = self.price_scaler.inverse_transform(y_test)
            y_pred_original = self.price_scaler.inverse_transform(y_pred)
        else:
            y_test_original = y_test
            y_pred_original = y_pred

        # –ú–µ—Ç—Ä–∏–∫–∏
        mse = mean_squared_error(y_test_original, y_pred_original)
        mae = mean_absolute_error(y_test_original, y_pred_original)
        r2 = r2_score(y_test_original, y_pred_original)

        print("üìà –û–¶–ï–ù–ö–ê –ú–û–î–ï–õ–ò:")
        print(f"MSE: {mse:.6f}")
        print(f"MAE: {mae:.6f}")
        print(f"R¬≤: {r2:.4f}")

        # –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ—Å—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
        if self.prediction_type == 'change':
            actual_directions = np.sign(y_test_original.flatten())
            pred_directions = np.sign(y_pred_original.flatten())
            direction_accuracy = np.mean(actual_directions == pred_directions)
            print(f"–¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è: {direction_accuracy:.4f}")

        return {
            'mse': mse,
            'mae': mae,
            'r2': r2,
            'y_test': y_test_original,
            'y_pred': y_pred_original
        }

    def predict(self, data: pd.DataFrame, current_index: int = None) -> Dict:
        """
        –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ü–µ–Ω—ã

        Args:
            data: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
            current_index: –∏–Ω–¥–µ–∫—Å –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è (–µ—Å–ª–∏ None, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–æ—Å–ª–µ–¥–Ω–∏–π)

        Returns:
            dict —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ–º –∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
        """
        if not self.is_trained:
            raise ValueError("–ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞")

        if current_index is None:
            current_index = len(data) - 1

        # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        features = self._create_features(data, current_index)
        if features is None:
            raise ValueError("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")

        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        features_scaled = self.feature_scaler.transform(features.reshape(1, -1))

        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        prediction = self.model.predict(features_scaled, verbose=0)[0][0]

        # –¢–µ–∫—É—â–∞—è —Ü–µ–Ω–∞
        current_price = data['close'].iloc[current_index]

        if self.prediction_type == 'price':
            # –û–±—Ä–∞—Ç–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è —Ü–µ–Ω—ã
            prediction_scaled = self.price_scaler.inverse_transform([[prediction]])
            predicted_price = prediction_scaled[0][0]
            predicted_change = (predicted_price - current_price) / current_price
        else:
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è
            predicted_change = prediction
            predicted_price = current_price * (1 + predicted_change)

        # –ê–Ω–∞–ª–∏–∑ —É—Ä–æ–≤–Ω–µ–π –¥–ª—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏
        strongest_levels = self.days_level.get_strongest_levels(timeframes=['1H', '4H', '1D'], top_n=10)
        level_info = self._calculate_distance_to_levels(current_price, strongest_levels)
        volatility_info = self._calculate_volatility_features(data.iloc[current_index-10:current_index+1])

        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
        strategy = self._determine_strategy(current_price, predicted_price, level_info, volatility_info)

        return {
            'current_price': current_price,
            'predicted_price': predicted_price,
            'predicted_change': predicted_change,
            'predicted_change_percent': predicted_change * 100,
            'strategy': strategy,
            'level_info': level_info,
            'volatility_info': volatility_info,
            'confidence': self._calculate_confidence(features_scaled)
        }

    def _determine_strategy(self, current_price: float, predicted_price: float,
                          level_info: Dict, volatility_info: Dict) -> str:
        """
        –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–æ—Ä–≥–æ–≤–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è

        Args:
            current_price: —Ç–µ–∫—É—â–∞—è —Ü–µ–Ω–∞
            predicted_price: –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è —Ü–µ–Ω–∞
            level_info: –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± —É—Ä–æ–≤–Ω—è—Ö
            volatility_info: –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏

        Returns:
            —Å—Ç—Ä–æ–∫–∞ —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
        """
        price_change = predicted_price - current_price

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –±–ª–∏–∑–æ—Å—Ç—å –∫ —É—Ä–æ–≤–Ω—è–º
        near_support = level_info['nearest_support_dist'] < 0.01  # –í –ø—Ä–µ–¥–µ–ª–∞—Ö 1%
        near_resistance = level_info['nearest_resistance_dist'] < 0.01
        near_mirror = level_info['nearest_mirror_dist'] < 0.01

        # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 1: –û—Ç–±–æ–π –æ—Ç —Å–∏–ª—å–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è
        if near_support and level_info['nearest_support_strength'] > 5:
            if price_change > 0:
                return "–û—Ç–±–æ–π –æ—Ç —Å–∏–ª—å–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏ - –ø–æ–∫—É–ø–∫–∞"
            else:
                return "–í–æ–∑–º–æ–∂–Ω—ã–π –ø—Ä–æ–±–æ–π —É—Ä–æ–≤–Ω—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏ - –ø—Ä–æ–¥–∞–∂–∞"

        if near_resistance and level_info['nearest_resistance_strength'] > 5:
            if price_change < 0:
                return "–û—Ç–±–æ–π –æ—Ç —Å–∏–ª—å–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è —Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏—è - –ø—Ä–æ–¥–∞–∂–∞"
            else:
                return "–í–æ–∑–º–æ–∂–Ω—ã–π –ø—Ä–æ–±–æ–π —É—Ä–æ–≤–Ω—è —Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏—è - –ø–æ–∫—É–ø–∫–∞"

        # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 2: –ü—Ä–æ–±–æ–π —É—Ä–æ–≤–Ω—è –ø—Ä–∏ –Ω–∏–∑–∫–æ–π –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
        if volatility_info['is_accumulation']:
            if price_change > 0 and near_resistance:
                return "–ü—Ä–æ–±–æ–π —Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏—è –ø—Ä–∏ –Ω–∏–∑–∫–æ–π –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ - –ø–æ–∫—É–ø–∫–∞"
            elif price_change < 0 and near_support:
                return "–ü—Ä–æ–±–æ–π –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –ø—Ä–∏ –Ω–∏–∑–∫–æ–π –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ - –ø—Ä–æ–¥–∞–∂–∞"

        # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 3: –ó–µ—Ä–∫–∞–ª—å–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å
        if near_mirror and level_info['nearest_mirror_strength'] > 3:
            mirror_distance = level_info['nearest_mirror_dist'] * current_price
            if price_change > 0:
                return f"–û—Ç—Ä–∞–±–æ—Ç–∫–∞ –∑–µ—Ä–∫–∞–ª—å–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è –≤–≤–µ—Ä—Ö - —Ü–µ–ª—å +{mirror_distance:.2f}"
            else:
                return f"–û—Ç—Ä–∞–±–æ—Ç–∫–∞ –∑–µ—Ä–∫–∞–ª—å–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è –≤–Ω–∏–∑ - —Ü–µ–ª—å -{mirror_distance:.2f}"

        # –û–±—â–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è
        if abs(price_change) > 0.02:  # –ó–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ –¥–≤–∏–∂–µ–Ω–∏–µ > 2%
            direction = "–ø–æ–∫—É–ø–∫–∞" if price_change > 0 else "–ø—Ä–æ–¥–∞–∂–∞"
            return f"–ó–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ –¥–≤–∏–∂–µ–Ω–∏–µ - {direction}"

        return "–ë–æ–∫–æ–≤–æ–µ –¥–≤–∏–∂–µ–Ω–∏–µ - –æ–∂–∏–¥–∞–Ω–∏–µ"

    def _calculate_confidence(self, features_scaled: np.ndarray) -> float:
        """
        –†–∞—Å—á–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –≤ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏ (–ø—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞)

        Args:
            features_scaled: –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏

        Returns:
            —É—Ä–æ–≤–µ–Ω—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –æ—Ç 0 –¥–æ 1
        """
        # –î–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—Ä–∞—Ç–Ω—É—é –¥–∏—Å–ø–µ—Ä—Å–∏—é –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        feature_variance = np.var(features_scaled)
        confidence = 1 / (1 + feature_variance)

        return min(max(confidence, 0.1), 0.9)  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –æ—Ç 0.1 –¥–æ 0.9

    def plot_training_history(self):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∏—Å—Ç–æ—Ä–∏–∏ –æ–±—É—á–µ–Ω–∏—è"""
        if self.training_history is None:
            print("–ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞")
            return

        plt.figure(figsize=(12, 4))

        # –ì—Ä–∞—Ñ–∏–∫ –ø–æ—Ç–µ—Ä—å
        plt.subplot(1, 2, 1)
        plt.plot(self.training_history.history['loss'], label='Training Loss')
        plt.plot(self.training_history.history['val_loss'], label='Validation Loss')
        plt.title('Model Loss')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.legend()

        # –ì—Ä–∞—Ñ–∏–∫ MAE
        plt.subplot(1, 2, 2)
        plt.plot(self.training_history.history['mae'], label='Training MAE')
        plt.plot(self.training_history.history['val_mae'], label='Validation MAE')
        plt.title('Model MAE')
        plt.xlabel('Epoch')
        plt.ylabel('MAE')
        plt.legend()

        plt.tight_layout()
        plt.show()

    def plot_predictions(self, n_samples=100):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π"""
        if self.model is None:
            print("‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞!")
            return

        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        eval_results = self.evaluate_model()
        y_test = eval_results['y_test'][:n_samples]
        y_pred = eval_results['y_pred'][:n_samples]

        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 10))

        # –ì—Ä–∞—Ñ–∏–∫ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
        ax1.plot(y_test.flatten(), label='Actual', alpha=0.7)
        ax1.plot(y_pred.flatten(), label='Predicted', alpha=0.7)
        ax1.set_title(f'–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –∏ —Ä–µ–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π (–ø–µ—Ä–≤—ã–µ {n_samples} —Ç–æ—á–µ–∫)')
        ax1.set_xlabel('–í—Ä–µ–º—è')
        ax1.set_ylabel('–¶–µ–Ω–∞')
        ax1.legend()
        ax1.grid(True)

        # –ì—Ä–∞—Ñ–∏–∫ –æ—à–∏–±–æ–∫
        errors = y_test.flatten() - y_pred.flatten()
        ax2.plot(errors, color='red', alpha=0.7)
        ax2.axhline(y=0, color='black', linestyle='--')
        ax2.set_title('–û—à–∏–±–∫–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π')
        ax2.set_xlabel('–í—Ä–µ–º—è')
        ax2.set_ylabel('–û—à–∏–±–∫–∞')
        ax2.grid(True)

        plt.tight_layout()
        return fig

    def save_model(self, filepath: str):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
        if self.model is None:
            raise ValueError("–ú–æ–¥–µ–ª—å –Ω–µ —Å–æ–∑–¥–∞–Ω–∞")

        self.model.save(filepath)
        print(f"–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {filepath}")

    def load_model(self, filepath: str):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏"""
        self.model = keras.models.load_model(filepath)
        self.is_trained = True
        print(f"–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ {filepath}")
    
    
    
        
    # ==–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è==
    def example_usage():
        """
        –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Å–∏—Å—Ç–µ–º—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Ü–µ–Ω—ã
        """
        # –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        np.random.seed(42)
        dates = pd.date_range('2025-01-01', periods=1000, freq='1D')

        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö OHLC –¥–∞–Ω–Ω—ã—Ö
        price = 100
        prices = [price]

        for i in range(999):
            change = np.random.normal(0, 0.02)  # 2% —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ
            price *= (1 + change)
            prices.append(price)

        # –°–æ–∑–¥–∞–Ω–∏–µ OHLC –¥–∞–Ω–Ω—ã—Ö
        data = pd.DataFrame(index=dates)
        data['close'] = prices
        data['open'] = data['close'].shift(1) * (1 + np.random.normal(0, 0.005, len(data)))
        data['high'] = np.maximum(data['open'], data['close']) * (1 + np.abs(np.random.normal(0, 0.01, len(data))))
        data['low'] = np.minimum(data['open'], data['close']) * (1 - np.abs(np.random.normal(0, 0.01, len(data))))
        data['volume'] = np.random.uniform(100, 1000, len(data))  # –µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è
        data = data.dropna()

        print("–°–æ–∑–¥–∞–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ —É—Ä–æ–≤–Ω–µ–π...")

        # –ó–∞–º–µ–Ω–∏—Ç–µ–ª—å DaysLevel
        class MockDaysLevel:
            def __init__(self, data):
                self.data = data
                self.timeframe = '1D'

            def get_strongest_levels(self, timeframes=None, top_n=10):
                # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ñ–∏–∫—Ç–∏–≤–Ω—ã–µ —É—Ä–æ–≤–Ω–∏
                current_price = self.data['close'].iloc[-1]
                levels = []
                for i in range(top_n):
                    level = current_price * (1 + np.random.normal(0, 0.05))
                    strength = np.random.uniform(1, 10)
                    levels.append((
                        self.data.index[-1],
                        level,
                        strength,
                        '1H',
                        np.random.choice(['support', 'resistance', 'mirror']),
                        np.random.choice(['up', 'down', 'neutral'])
                    ))
                return levels

        # –î–æ–±–∞–≤–ª—è–µ–º ATRI (–∑–∞–≥–ª—É—à–∫–∞)
        data['atri'] = data['close'].rolling(14).std()

        days_level = MockDaysLevel(data)

        print("–°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è...")
        predictor = CriptoPredictionNN(
            days_level=days_level,
            lookback_period=20,
            prediction_horizon=5,
            prediction_type = 'price'
        )

        print("–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
        try:
            history = predictor.train(data, epochs=50, batch_size=16, verbose=1)

            print("\n–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –¥–∞–Ω–Ω—ã—Ö...")
            prediction = predictor.predict(data)

            print("\n" + "="*50)
            print("–†–ï–ó–£–õ–¨–¢–ê–¢ –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–Ø")
            print("="*50)
            print(f"–¢–µ–∫—É—â–∞—è —Ü–µ–Ω–∞: {prediction['current_price']:.4f}")
            print(f"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è —Ü–µ–Ω–∞: {prediction['predicted_price']:.4f}")
            print(f"–û–∂–∏–¥–∞–µ–º–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ: {prediction['predicted_change_percent']:.2f}%")
            print(f"–°—Ç—Ä–∞—Ç–µ–≥–∏—è: {prediction['strategy']}")
            print(f"–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {prediction['confidence']:.2f}")

            # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∏—Å—Ç–æ—Ä–∏–∏ –æ–±—É—á–µ–Ω–∏—è
            predictor.plot_training_history()

            # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
            predictor.plot_predictions()

        except Exception as e:
            print(f"–û—à–∏–±–∫–∞: {e}")
            import traceback
            traceback.print_exc()

    if __name__ == "__main__":
        example_usage()

    
